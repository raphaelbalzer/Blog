---
title: "Hatespeech Klassifikation"
author: "Raphael Balzer"
date: "2023-11-25"
image: "gemaelde.jpeg"
categories:
  - Textanalyse
  - Klassifikation
  - tidymodels
---

# Hatespeech Klassifikation

Klassifikation von Hatespeech auf Grundlage der Germeval-Daten.

## Vorbereitung
### Pakte laden
```{r output=FALSE}
library(tidymodels)
library(textrecipes)
library(datawizard)
library(lightgbm)
library(bonsai)
library(vip)
data("sentiws", package = "pradadata")
```

### Datenimport
Bei den Daten handelt es sich um die Trainings- und Testdaten (deutsche Tweets) aus der GermEval 2018 Shared Task zum Erkennen von beleidigender Sprache.

```{r}
d_train <- 
  data_read("germeval2018.training.txt",
         header = FALSE,
         quote = "")
d_test <- 
  data_read("germeval2018.test.txt",
         header = FALSE,
         quote = "")
names(d_train) <- c("text", "c1", "c2")
names(d_test) <- c("text", "c1", "c2")
```
## Feature Engineering
Ziel ist es, auf Grundlage der Tweets einige nützliche Features zu generieren, die sich als Prädiktor für die AV (Hatespeech oder nicht) eignen.

```{r}
rec1 <-
  recipe(c1 ~ ., data = d_train) %>% 
  update_role(c2, new_role = "ignore") %>%  
  step_text_normalization(text) %>%
  step_tokenize(text, token = "words") %>% 
  step_stem(text) %>% 
  step_tokenfilter(text, max_tokens = 1e2) %>%
  step_stopwords(text, language = "de", stopword_source = "snowball") %>%  
  step_tfidf(text)
```

```{r}
baked <- rec1 %>% 
  prep() %>% 
  bake(new_data = NULL)
baked
```

## Modellierung
### Modelle definieren
Ich verwende für die Modellierung zum einen einen K-Nearest-Neighbour-Algorithums und zum anderen LightGBM.

```{r}
knn <- 
  nearest_neighbor(
  neighbors = tune(),
  weight_func = tune(),
  dist_power = tune()
) %>% 
  set_engine("kknn") %>% 
  set_mode("classification") %>% 
  translate()
  
lightgbm <- 
  boost_tree(
  mtry = tune(), 
  trees = tune(), 
  tree_depth = tune(), 
  learn_rate = tune(), 
  min_n = tune(), 
  loss_reduction = tune()
  ) %>%
  set_engine("lightgbm") %>%
  set_mode("classification") %>%
  translate()
```

### Workflowset erstellen

```{r}
preproc <- list(rec1 = rec1)

models <- list(lightgbm = lightgbm, knn = knn)

all_workflows <- workflow_set(preproc, models)

model_set <-
all_workflows %>% 
workflow_map(
  resamples = vfold_cv(d_train,
  v = 2, 
  repeats = 1),
  grid = 5,
  seed = 42,
  verbose = TRUE)
```

### Ergebnisse
```{r}
tune::autoplot(model_set) +
  theme(legend.position = "bottom")
```

```{r}
model_set %>% 
  collect_metrics() %>% 
  arrange(-mean)
```
LightGBM hat deutlich besser abgeschnitten als KNN. Wählen wir nun das beste Modell aus und fitten es:

### Finalisieren
```{r}
best_model_params <- 
  extract_workflow_set_result(model_set, "rec1_lightgbm") %>% 
  select_best()
```

```{r}
best_wf <- 
all_workflows %>% 
  extract_workflow("rec1_lightgbm")

best_wf_finalized <- 
  best_wf %>% 
  finalize_workflow(best_model_params)

fit_final <- fit(best_wf_finalized, data = d_train)
```

```{r}
fit_final %>% 
  extract_fit_parsnip() %>% 
  vip() 
```
Die tfidf-Features scheinen die wichtigsten Features zu sein, gerade wenn es um Angela Merkel geht; interessant.

## Vorhersagen
```{r}
preds <- predict(fit_final, d_test)
preds
```

### Bestimmen der Vorhersagegüte im Test-Sample
```{r}
d_test <-
  d_test %>%  
   bind_cols(preds) %>% 
  mutate(c1 = as.factor(c1))
d_test
```


```{r}
my_metrics <- metric_set(accuracy)
my_metrics(d_test,
           truth = c1,
           estimate = .pred_class)
```