[
  {
    "objectID": "posts/Hate Speech auf Reddit/Hatespeech_Reddit.html",
    "href": "posts/Hate Speech auf Reddit/Hatespeech_Reddit.html",
    "title": "Hate Speech auf Reddit",
    "section": "",
    "text": "Ziel dieser Analyse ist es, die Reddit-Threads, deren urspr√ºngliche Posts das Stichwort ‚ÄúKanye West‚Äù enthalten, in Bezug auf Sentiment, Schimpfw√∂rter und Hate-Speech zu untersuchen. Hierbei ist vor allem die Ver√§nderung der Sentimente der Posts im Zeitverlauf interessant. Dieser Post soll au√üerdem der Antwort auf die Frage n√§herkommen, ob die Nutzung der kostenlosen Reddit-API eine Alternative zur inzwischen kostenpflilchtigen Twitter-API darstellt, um Hate-Speech auf Social-Media-Plattformen zu analysieren. Der Post l√§sst sich grob in zwei Teile gliedern, n√§mlich wird zun√§chst die Analyse der Posts und Kommentare in Bezug auf Sentimente und Themen vorgenommen, woraufhin die Beitr√§ge auf im zweiten Teil auf Hate Speech gepr√ºft werden.\n\nlibrary(tokenizers)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(textdata)\nlibrary(ggthemes)\nlibrary(topicmodels)\nlibrary(tm)\nlibrary(stringr)\nlibrary(RedditExtractoR)\nlibrary(httr)\n\n\n\n\n\nDie Posts werden mit Hilfe des Pakets RedditExtractoR, welches die Reddit-API anspricht, extrahiert. Ich lade alle Posts, die das Keyword ‚ÄúKanye West‚Äù enthalten (und innerhalb des Download-Limits sind). Dadurch dass ich das API Download-Limit f√ºr heute bereits erreicht habe, importiere ich die Posts und Kommentare als Csv-Datei.\n\nposts &lt;- find_thread_urls(\n  keywords = \"Kanye West\",\n  sort_by=\"top\", \n  period = \"all\"\n  )\nstr(posts)\n\n\nposts &lt;- read_csv(\"posts.csv\")\n\nNew names:\nRows: 228 Columns: 8\n‚îÄ‚îÄ Column specification\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Delimiter: \",\" chr\n(5): ...1, title, text, subreddit, url dbl (2): timestamp, comments date (1):\ndate_utc\n‚Ñπ Use `spec()` to retrieve the full column specification for this data. ‚Ñπ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n‚Ä¢ `` -&gt; `...1`\n\n\n\n\n\nMit der Funktion get_thread_content() ist es m√∂glich, bis zu 500 Kommentare zu einer Post-URL herunterzuladen. Um maximal 500 Kommentare zu allen n Posts herunterzuladen, wende ich eine Schleife an. Die Ausgabe ist dann eine Liste, die zwei Dataframes enth√§lt. Ich extrahiere den Dataframe comments und speichere jeden Dataframe zu jeder URL in einer Liste ab. Manchmal kann es zu Problemen bei der Zusammenf√ºhrung der Listenelemente zu einem Dataframe kommen, da die Spalte comment_id in manchen F√§llen von der Standardfornatierung als Character abweicht und als Integer gespeichert wird. Dieses Problem l√∂se ich, indem ich alle solche Spalten in Character umwandle. Zuletzt entferne ich noch sowohl alle entfernten und gel√∂schten Posts als auch Links und Zahlen.\n\ncomments_list &lt;- list()\n\nfor (i in 1:nrow(posts)) {\n  comments &lt;- get_thread_content(posts$url[i])$comments\n  comments_list[[i]] &lt;- comments\n}\n\numwandlung_character &lt;- function(df) {\n  if (\"comment_id\" %in% names(df) && is.integer(df$comment_id)) {\n    df$comment_id &lt;- as.character(df$comment_id)\n  }\n  return(df)\n}\n\nliste_dataframes_umgewandelt &lt;- lapply(comments_list, umwandlung_character)\nall_comments &lt;- bind_rows(liste_dataframes_umgewandelt)\nall_comments &lt;- all_comments %&gt;%\n  mutate(comment = str_remove_all(comment, pattern = 'http[s]?://\\\\S+|\\\\d+')) %&gt;%\n  mutate(timestamp = as_datetime(timestamp, origin = \"1970-01-01\")) %&gt;% \n  select(timestamp, comment, comment_id, url)\nall_comments &lt;- all_comments %&gt;%\n  filter(!grepl(\"\\\\[deleted\\\\]|\\\\[removed\\\\]\", comment))\n\n\nall_comments &lt;- read_csv(\"all_comments.csv\")\n\nNew names:\nRows: 98044 Columns: 5\n‚îÄ‚îÄ Column specification\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Delimiter: \",\" chr\n(3): comment, comment_id, url dbl (2): ...1, timestamp\n‚Ñπ Use `spec()` to retrieve the full column specification for this data. ‚Ñπ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n‚Ä¢ `` -&gt; `...1`\n\n\nIm Folgenden werden die Kommentare und Posts einzeln betrachtet. Dies hat den Grund, dass Reddit-Posts tendenziell mehr aus sachlichen Inhalten bestehen, w√§hrend die Kommentarsektion inhaltlich freier und dadaurch, dass sich dort noch einmal ganz eigene Themen entspinnen, nicht mit den Posts vergleichbar sind. Hinzu kommt, dass die Anzahl der Kommentare die der Posts um ein Vielfaches √ºbersteigt, sodass diese separat analysiert werden sollten.\n\n\n\nIm Folgenden wandle ich die Posts und Kommentare in Tokens um, entferne alle Links und Zahlen und wandle timestamp in ein Datumsobjekt um. Um alle Text-Inhalte der Posts zu erfassen, vereine ich die Titel der Posts mit den Posts, da es viele Posts gibt, deren Kernaussage im Titel steht, die durch ein Bild verdeutlicht wird.\n\npoststoken &lt;- posts %&gt;%\n  unite(text, c(title, text)) %&gt;%\n  mutate(text = str_remove_all(text, pattern = '\"http[s]?://\\\\S+\"|\\\\d+')) %&gt;%\n  mutate(timestamp = as_datetime(timestamp, origin = \"1970-01-01\")) %&gt;% \n  unnest_tokens(word, text)\nnrow(poststoken)\n\n[1] 22897\n\nlength(unique(poststoken$id))\n\nWarning: Unknown or uninitialised column: `id`.\n\n\n[1] 0\n\n\n\ncommstoken &lt;- all_comments %&gt;%\n  mutate(timestamp = as_datetime(timestamp, origin = \"1970-01-01\")) %&gt;% \n  unnest_tokens(word, comment)\n\n\n\n\nNun werden alle Stopwords entfernt. Ich gehe davon aus, dass die Kommentare und Posts fast ausschlie√ülich englischer Sprache sind. F√ºr den Fall, dass sich im Datensatz jedoch sowohl deutsch- als auch englischsprachige Posts finden, kombiniere ich zwei Stopwords-Lexika (deutsch und englisch) zu einem.\n\ndata(stopwords_de, package = \"lsa\")\ndata(stopwords_en, package = \"lsa\")\nstopwords_en &lt;- tibble(word = stopwords_en)\nstopwords_de &lt;- tibble(word = stopwords_de)\nstopwords &lt;- bind_rows(stopwords_de, stopwords_en)\n\n\npoststoken &lt;- poststoken %&gt;%\n  anti_join(stopwords)\n\nJoining with `by = join_by(word)`\n\nnrow(poststoken)\n\n[1] 12280\n\nlength(unique(poststoken$id))\n\nWarning: Unknown or uninitialised column: `id`.\n\n\n[1] 0\n\n\n\ncommstoken &lt;- commstoken %&gt;%\n  anti_join(stopwords)\n\nJoining with `by = join_by(word)`\n\n\n\n\n\nF√ºr die Sentimentanalyse gilt dasselbe wie f√ºr das Stopwords-Lexikon: Ich m√∂chte, dass es zweisprachig ist. Die gew√§hlten Lexika afinn und sentiws haben jedoch nicht dieselbe Skalierung, weshalb ich noch eine Min-Max-Normalisierung vornehme, um eine Vergleichbarkeit der deutschen und englischen Sentimentwerte zu gew√§hrleisten.\n\nsenti_en &lt;- get_sentiments(\"afinn\") %&gt;% \n  mutate(neg_pos = case_when(value &gt; 0 ~ \"pos\",\n                             TRUE ~ \"neg\"))\n\ndata(sentiws, package = \"pradadata\")\nsentiws &lt;- sentiws %&gt;% \n  select(word, value, neg_pos)\n\nmin_max_normalize &lt;- function(x, old_min, old_max, new_min, new_max) {\n  return (((x - old_min) / (old_max - old_min) * (new_max - new_min)) + new_min)\n}\n\nsenti_en &lt;- senti_en %&gt;% \n  mutate(value = min_max_normalize(value, -5, 5, -1, 1))\n\nsenti &lt;- bind_rows(sentiws, senti_en)\n\n\npoststoken_senti &lt;- poststoken %&gt;%\ninner_join(senti)\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., senti): Detected an unexpected many-to-many relationship between `x` and `y`.\n‚Ñπ Row 88 of `x` matches multiple rows in `y`.\n‚Ñπ Row 4591 of `y` matches multiple rows in `x`.\n‚Ñπ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nnrow(poststoken_senti)\n\n[1] 1269\n\nlength(unique(poststoken_senti$timestamp))\n\n[1] 124\n\n\n\ncommstoken_senti &lt;- commstoken %&gt;% \n  inner_join(senti)\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., senti): Detected an unexpected many-to-many relationship between `x` and `y`.\n‚Ñπ Row 778 of `x` matches multiple rows in `y`.\n‚Ñπ Row 5008 of `y` matches multiple rows in `x`.\n‚Ñπ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\nZuletzt werden noch die Sentimentwerte aller Posts in einem Jahr zusammengefasst und mit der Anzahl der Posts gewichtet.\n\npostssenti &lt;- poststoken_senti %&gt;% \n  mutate(year = year(timestamp)) %&gt;%\n  group_by(year) %&gt;%\n  summarize(value = mean(value),\n            postcount = length(unique((timestamp)))) %&gt;% \n  mutate(sentiment = (value * postcount) / sum(postcount))\n\nnrow(postssenti)\n\n[1] 9\n\n\n\ncommssenti &lt;- commstoken_senti %&gt;%\n  mutate(year = year(timestamp)) %&gt;% \n  group_by(year) %&gt;% \n  summarize(value = mean(value),\n            postcount = length(unique((timestamp)))) %&gt;% \n  mutate(sentiment = (value * postcount) / sum(postcount))\nnrow(commssenti)\n\n[1] 10\n\n\n\npostssenti %&gt;% \n  ggplot(aes(year, sentiment)) + \n  geom_line(linewidth = 1, colour = \"#6fb899\") +\n  labs(title = \"Sentimentwerte der Posts im Zeitverlauf\",\n       x = \"Jahr\",\n       y = \"Sentiment\") +\n  theme_minimal()\n\n\n\n\n\ncommssenti %&gt;% \n  ggplot(aes(year, sentiment)) + \n  geom_line(linewidth = 1, colour = \"#6fb899\") +\n  scale_x_continuous(breaks = 2013:2024)+\n  labs(title = \"Sentimentwerte der Kommentare im Zeitverlauf\",\n       x = \"Jahr\",\n       y = \"Sentiment\") +\n  theme_minimal()\n\n\n\n\nDie Sentimentwerte im Zeitverlauf sind √ºberaus interessant. Auch wenn der Sentimentwert um den Nullbereich liegt, denke ich dennoch, dass er eine gewisse Aussagekraft hat. Gerade wenn er im Jahr 2022 sowohl bei den Posts als auch bei den Kommentaren rapide einbricht, um seinen absoluten Tiefpunkt zu erreichen, sollte man genauer hinsehen. Im Jahr 2022 stand es um die √∂ffentliche Meinung zu Kanye West so schlecht wie noch nie zuvor. Durch st√§ndige antisemitische √Ñu√üerungen, das Posten eines Hakenkreuzes und Tragen eines ‚ÄúWhite Lifes Matter‚Äù-Hoodies erreichte er die Sperrung seiner Social Media Accounts, die K√ºndigung der Kooperation mit Adidas und die Ausl√∂sung eines Shit-Storms in den sozialen Medien. Dieser Zusammenhang k√∂nnte obige Diagramme erkl√§ren.\n\n\n\n\npoststoken_senti %&gt;%\n  count(word, neg_pos, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  group_by(neg_pos) %&gt;%\n  slice_max(n, n = 10)%&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot(aes(n, word, fill = neg_pos)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~neg_pos, scales = \"free_y\") +\n  labs(x = \"H√§ufigkeit\",\n       y = \"Wort\") +\n  theme_minimal() +\n  scale_fill_tableau(palette = \"Nuriel Stone\")\n\n\n\n\nDie h√§ufigsten positiven W√∂rter sind insofern interessant, als sie den Themen des christlichen Glaubens widerspiegeln. Denn Kanye West bekennt sich regelm√§√üig in Interviews und Tweets zum Christentum. Inwiefern seine antisemitschen √Ñu√üerungen mit diesem Glauben vereinbar sind, sei mal dahingestellt.\n\ncomms_bigram &lt;- \n  all_comments %&gt;%\n  unnest_tokens(bigram, comment, token = \"ngrams\", n = 2) %&gt;%\n  filter(!is.na(bigram))\n\ncomms_bigram &lt;- comms_bigram %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")%&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\ncomms_bigram %&gt;%\n  unite(bigram, word1, word2, sep = \" \") %&gt;%\n  count(bigram, sort = TRUE) %&gt;%\n  slice_max(n, n = 10)%&gt;%\n  mutate(bigram = reorder(bigram, n)) %&gt;%\n  ggplot(aes(n, bigram)) +\n  geom_col(fill = \"#8175aa\") +\n  labs(title = \"Bigramme nach H√§ufigkeit\",\n       x = \"H√§ufigkeit\",\n       y = \"Bigram\") +\n  theme_minimal()\n\n\n\n\nInteressant ist bei der Betrachtung der h√§ufigsten Bigramme, die in den Kommentaren vorkommen, wie pr√§sent das Thema der psychischen St√∂rungen ist. Die Mutma√üung, dass in den Kommentaren √ºber Kanye Wests mentale Gesundheit diskutiert wird, ist nicht unplausibel.\n\n\n\n\nposts_dtm2 &lt;- commstoken_senti %&gt;% \n  mutate(timestamp = as_datetime(timestamp),\n         year = year(timestamp)) %&gt;% \n  filter(year == 2022) %&gt;%\n  select(word) %&gt;% \n  DocumentTermMatrix(commstoken_senti)\n\nWarning: Unknown or uninitialised column: `tokenize`.\n\n\nWarning: Unknown or uninitialised column: `tolower`.\n\n\nWarning: Unknown or uninitialised column: `stopwords`.\nUnknown or uninitialised column: `stopwords`.\n\n\nWarning: Unknown or uninitialised column: `dictionary`.\n\n\nWarning: Unknown or uninitialised column: `bounds`.\n\n\nWarning: Unknown or uninitialised column: `wordLengths`.\n\n\nWarning: Unknown or uninitialised column: `removePunctuation`.\n\n\nWarning: Unknown or uninitialised column: `removeNumbers`.\n\n\nWarning: Unknown or uninitialised column: `stemming`.\n\n\nWarning: Unknown or uninitialised column: `bounds`.\n\n\nWarning: Unknown or uninitialised column: `weighting`.\n\nposts_lda2 &lt;- LDA(posts_dtm2, k = 4, control = list(seed = 42))\n\nposts_themen2 &lt;- tidy(posts_lda2, matrix = \"beta\")\n\nposts_themen2 &lt;- posts_themen2 %&gt;%\n  group_by(topic) %&gt;%\n  slice_max(beta, n = 7) %&gt;% \n  ungroup() %&gt;%\n  arrange(topic, -beta)\n\nposts_themen2 %&gt;%\n  mutate(term = reorder_within(term, beta, topic)) %&gt;%\n  ggplot(aes(beta, term, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ topic, scales = \"free\") +\n  scale_y_reordered() +\n  labs(title = \"Kommentarthemen in 2022 \") +\n  theme_minimal() +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\nDie Analyse der Kommentarthemen des Jahres 2022 deuten ebenfalls auf Kanye Wests √Ñu√üerungen hin, da im ersten Thema dem Wort ‚Äúhitler‚Äù eine gewisse Bedeutung zugeordnet wird.\n\n\n\n\nGerade in Zusammenhang mit konktroversen Themen und Personen ist die Analyse von Hate Speech in den sozialen Medien relevant. In Bezug auf die Kommentare zu Kanye West Posts ist es denke ich sehr interessant zu sehen, welcher Anteil der Kommentare als Hate Speech gilt. F√ºr die Vorhersage wende ich Zero-Shot-Klassifikation mit Hilfe des vortrainierten Large Language Modells LFTW R4 Target von facebook an, welches ich √ºber das Modul transformers von Huggingface anspreche, an.\n\n\nZun√§chst lade ich alle erforderlichen Module sowie das Modell. Der Code zur Verwendung des pipeline-Befehls wird hilfreicherweise von Huggingface bereitgestellt.\n\nlibrary(reticulate)\n\nWarning: package 'reticulate' was built under R version 4.2.3\n\nuse_virtualenv(\"C:/Users/rapha/venv\")\n\n\nimport pandas as pd\nimport tensorflow as tf\n\nWARNING:tensorflow:From C:\\Users\\rapha\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\nfrom transformers import pipeline\n\nclassifier = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\")\n\nWARNING:tensorflow:From C:\\Users\\rapha\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n\n\n\n\n\nF√ºr die Klassifikation von Hate-Speech ziehe ich aus allen Kommentaren eine zuf√§llige Stichprobe, da RoBERTa nur eine Maximall√§nge von 513 Inputs akzeptiert.\n\nset.seed(123)\ncomments_sample &lt;- all_comments %&gt;%\n  sample_n(size = 513, replace = FALSE)\n\ncomments_short &lt;- comments_sample$comment\n\nNun lade ich die Kommentare der Stichprobe in das Modell.\n\ncomments = r.comments_short\nresult = classifier(comments)\n\nAnschlie√üend f√ºge ich der Stichprobe das Ergebnis der Klassifikation als neue Spalte hinzu.\n\nresult &lt;- py$result\nlabels &lt;- lapply(result, function(element) element$label)\ncomments_hate &lt;- cbind(comments_sample, hatespeech = unlist(labels)) %&gt;%\n  select(timestamp, comment, hatespeech, comment_id, url)\n\n\n\n\nIm Folgenden untersuche ich die als Hate Speech klassifizierten Kommentare etwas n√§her, indem ich den Anteil der Hate Speech im Jahresverlauf sowie den Zusammenhang mit negativem Sentiment betrachte.\n\ncomments_hate %&gt;%\n   count(hatespeech == \"hate\")\n\n\n\n  \n\n\n\n\ncomments_hate %&gt;%\n  mutate(timestamp = as_datetime(timestamp, origin = \"1970-01-01\"),\n         year = year(timestamp)) %&gt;%\n  group_by(year, hatespeech) %&gt;%\n  count() %&gt;%\n  ggplot(aes(x = year, y = n, fill = hatespeech)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Hatespeech-Kommentare im Zeitverlauf\",\n       x = \"Jahr\",\n       y = \"Anzahl\",\n       fill = \"Hate Speech\") +\n  scale_fill_tableau(\"Nuriel Stone\") +\n  theme_minimal()\n\n\n\n\nAuch wenn nur ein winziger Teil der Kommentare als Hate Speech klassifiziert wurde, ist in diesem Diagramm erkennbar, dass wieder im Jahr 2022 mit Abstand die meiste Hassrede auftrat.\n\ncommstokensenti_hate &lt;- comments_hate %&gt;% \n  filter(hatespeech == \"hate\") %&gt;% \n  unnest_tokens(word, comment) %&gt;% \n  inner_join(senti)\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., senti): Detected an unexpected many-to-many relationship between `x` and `y`.\n‚Ñπ Row 541 of `x` matches multiple rows in `y`.\n‚Ñπ Row 4906 of `y` matches multiple rows in `x`.\n‚Ñπ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ncommstokensenti_hate %&gt;% \n  summarise(mean(neg_pos == \"neg\"))\n\n\n\n  \n\n\n\n\ncomments_hate %&gt;% \n  filter(hatespeech == \"hate\") %&gt;% \n  select(comment)\n\n\n\n  \n\n\n\nNur die H√§lfte der als Hassrede klassifizierten Kommentare haben ein negatives Sentiment. Au√üerdem halte ich pers√∂nlich S√§tze wie ‚ÄúYou are an old one.‚Äù nicht f√ºr Hate Speech. In Kombination mit dem Fakt, dass nur 34 von 513 Tweets als Hate Speech erkannt wurden, lassen mich diese Ergebnisse vermuten, dass das Modell nicht allzu zuverl√§ssige Vorhersagen macht.\n\n\n\n\nEs l√§sst sich sagen, dass die Analyse durchaus interessante Erkenntnisse hervorgebracht hat. Die Sentimentwerte k√∂nnen in einen klaren Zusammenhang mit dem Verhalten Kanye Wests gesetzt werden. Allerdings unterliegen diese Erkenntnisse starken Limitationen. Zum einen ist die Anzahl der verwertbaren Posts verschwindend gering, was die Aussagekraft der Analyse dieser beeintr√§chtigt. Deshalb lag das Augenmerk auch st√§rker auf den Kommentaren. Die Schwankungen in den Sentimentwerten beeintr√§chtigen ebenfalls die Aussagekraft der gewonnenen Erkenntnisse, da diese infinitesimal klein ausfallen. Die Klassifikationen des RoBERTa-Modells halte ich ebenfalls f√ºr stark ausbauf√§hig. Es w√§re sinnvoll, in weiteren Analysen noch andere Large Language Modelle f√ºr diese Aufgabe auszuprobieren. Ziel der Analyse war es jedoch auch, zu sehen, ob Redditposts √§hnlich interessant f√ºr die Analyse von Social-Media-Foren sind wie Tweets. Diese Frage ist auf jeden Fall mit Ja zu beantworten, zum einen aufgrund der leichten Zug√§nglichkeit und zum anderen aufgrund des regen Themenaustausches in den Threads, wie er hier beobachtet wurde."
  },
  {
    "objectID": "posts/Hate Speech auf Reddit/Hatespeech_Reddit.html#analyse-der-posts-und-kommentare",
    "href": "posts/Hate Speech auf Reddit/Hatespeech_Reddit.html#analyse-der-posts-und-kommentare",
    "title": "Hate Speech auf Reddit",
    "section": "",
    "text": "Die Posts werden mit Hilfe des Pakets RedditExtractoR, welches die Reddit-API anspricht, extrahiert. Ich lade alle Posts, die das Keyword ‚ÄúKanye West‚Äù enthalten (und innerhalb des Download-Limits sind). Dadurch dass ich das API Download-Limit f√ºr heute bereits erreicht habe, importiere ich die Posts und Kommentare als Csv-Datei.\n\nposts &lt;- find_thread_urls(\n  keywords = \"Kanye West\",\n  sort_by=\"top\", \n  period = \"all\"\n  )\nstr(posts)\n\n\nposts &lt;- read_csv(\"posts.csv\")\n\nNew names:\nRows: 228 Columns: 8\n‚îÄ‚îÄ Column specification\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Delimiter: \",\" chr\n(5): ...1, title, text, subreddit, url dbl (2): timestamp, comments date (1):\ndate_utc\n‚Ñπ Use `spec()` to retrieve the full column specification for this data. ‚Ñπ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n‚Ä¢ `` -&gt; `...1`\n\n\n\n\n\nMit der Funktion get_thread_content() ist es m√∂glich, bis zu 500 Kommentare zu einer Post-URL herunterzuladen. Um maximal 500 Kommentare zu allen n Posts herunterzuladen, wende ich eine Schleife an. Die Ausgabe ist dann eine Liste, die zwei Dataframes enth√§lt. Ich extrahiere den Dataframe comments und speichere jeden Dataframe zu jeder URL in einer Liste ab. Manchmal kann es zu Problemen bei der Zusammenf√ºhrung der Listenelemente zu einem Dataframe kommen, da die Spalte comment_id in manchen F√§llen von der Standardfornatierung als Character abweicht und als Integer gespeichert wird. Dieses Problem l√∂se ich, indem ich alle solche Spalten in Character umwandle. Zuletzt entferne ich noch sowohl alle entfernten und gel√∂schten Posts als auch Links und Zahlen.\n\ncomments_list &lt;- list()\n\nfor (i in 1:nrow(posts)) {\n  comments &lt;- get_thread_content(posts$url[i])$comments\n  comments_list[[i]] &lt;- comments\n}\n\numwandlung_character &lt;- function(df) {\n  if (\"comment_id\" %in% names(df) && is.integer(df$comment_id)) {\n    df$comment_id &lt;- as.character(df$comment_id)\n  }\n  return(df)\n}\n\nliste_dataframes_umgewandelt &lt;- lapply(comments_list, umwandlung_character)\nall_comments &lt;- bind_rows(liste_dataframes_umgewandelt)\nall_comments &lt;- all_comments %&gt;%\n  mutate(comment = str_remove_all(comment, pattern = 'http[s]?://\\\\S+|\\\\d+')) %&gt;%\n  mutate(timestamp = as_datetime(timestamp, origin = \"1970-01-01\")) %&gt;% \n  select(timestamp, comment, comment_id, url)\nall_comments &lt;- all_comments %&gt;%\n  filter(!grepl(\"\\\\[deleted\\\\]|\\\\[removed\\\\]\", comment))\n\n\nall_comments &lt;- read_csv(\"all_comments.csv\")\n\nNew names:\nRows: 98044 Columns: 5\n‚îÄ‚îÄ Column specification\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Delimiter: \",\" chr\n(3): comment, comment_id, url dbl (2): ...1, timestamp\n‚Ñπ Use `spec()` to retrieve the full column specification for this data. ‚Ñπ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n‚Ä¢ `` -&gt; `...1`\n\n\nIm Folgenden werden die Kommentare und Posts einzeln betrachtet. Dies hat den Grund, dass Reddit-Posts tendenziell mehr aus sachlichen Inhalten bestehen, w√§hrend die Kommentarsektion inhaltlich freier und dadaurch, dass sich dort noch einmal ganz eigene Themen entspinnen, nicht mit den Posts vergleichbar sind. Hinzu kommt, dass die Anzahl der Kommentare die der Posts um ein Vielfaches √ºbersteigt, sodass diese separat analysiert werden sollten.\n\n\n\nIm Folgenden wandle ich die Posts und Kommentare in Tokens um, entferne alle Links und Zahlen und wandle timestamp in ein Datumsobjekt um. Um alle Text-Inhalte der Posts zu erfassen, vereine ich die Titel der Posts mit den Posts, da es viele Posts gibt, deren Kernaussage im Titel steht, die durch ein Bild verdeutlicht wird.\n\npoststoken &lt;- posts %&gt;%\n  unite(text, c(title, text)) %&gt;%\n  mutate(text = str_remove_all(text, pattern = '\"http[s]?://\\\\S+\"|\\\\d+')) %&gt;%\n  mutate(timestamp = as_datetime(timestamp, origin = \"1970-01-01\")) %&gt;% \n  unnest_tokens(word, text)\nnrow(poststoken)\n\n[1] 22897\n\nlength(unique(poststoken$id))\n\nWarning: Unknown or uninitialised column: `id`.\n\n\n[1] 0\n\n\n\ncommstoken &lt;- all_comments %&gt;%\n  mutate(timestamp = as_datetime(timestamp, origin = \"1970-01-01\")) %&gt;% \n  unnest_tokens(word, comment)\n\n\n\n\nNun werden alle Stopwords entfernt. Ich gehe davon aus, dass die Kommentare und Posts fast ausschlie√ülich englischer Sprache sind. F√ºr den Fall, dass sich im Datensatz jedoch sowohl deutsch- als auch englischsprachige Posts finden, kombiniere ich zwei Stopwords-Lexika (deutsch und englisch) zu einem.\n\ndata(stopwords_de, package = \"lsa\")\ndata(stopwords_en, package = \"lsa\")\nstopwords_en &lt;- tibble(word = stopwords_en)\nstopwords_de &lt;- tibble(word = stopwords_de)\nstopwords &lt;- bind_rows(stopwords_de, stopwords_en)\n\n\npoststoken &lt;- poststoken %&gt;%\n  anti_join(stopwords)\n\nJoining with `by = join_by(word)`\n\nnrow(poststoken)\n\n[1] 12280\n\nlength(unique(poststoken$id))\n\nWarning: Unknown or uninitialised column: `id`.\n\n\n[1] 0\n\n\n\ncommstoken &lt;- commstoken %&gt;%\n  anti_join(stopwords)\n\nJoining with `by = join_by(word)`\n\n\n\n\n\nF√ºr die Sentimentanalyse gilt dasselbe wie f√ºr das Stopwords-Lexikon: Ich m√∂chte, dass es zweisprachig ist. Die gew√§hlten Lexika afinn und sentiws haben jedoch nicht dieselbe Skalierung, weshalb ich noch eine Min-Max-Normalisierung vornehme, um eine Vergleichbarkeit der deutschen und englischen Sentimentwerte zu gew√§hrleisten.\n\nsenti_en &lt;- get_sentiments(\"afinn\") %&gt;% \n  mutate(neg_pos = case_when(value &gt; 0 ~ \"pos\",\n                             TRUE ~ \"neg\"))\n\ndata(sentiws, package = \"pradadata\")\nsentiws &lt;- sentiws %&gt;% \n  select(word, value, neg_pos)\n\nmin_max_normalize &lt;- function(x, old_min, old_max, new_min, new_max) {\n  return (((x - old_min) / (old_max - old_min) * (new_max - new_min)) + new_min)\n}\n\nsenti_en &lt;- senti_en %&gt;% \n  mutate(value = min_max_normalize(value, -5, 5, -1, 1))\n\nsenti &lt;- bind_rows(sentiws, senti_en)\n\n\npoststoken_senti &lt;- poststoken %&gt;%\ninner_join(senti)\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., senti): Detected an unexpected many-to-many relationship between `x` and `y`.\n‚Ñπ Row 88 of `x` matches multiple rows in `y`.\n‚Ñπ Row 4591 of `y` matches multiple rows in `x`.\n‚Ñπ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nnrow(poststoken_senti)\n\n[1] 1269\n\nlength(unique(poststoken_senti$timestamp))\n\n[1] 124\n\n\n\ncommstoken_senti &lt;- commstoken %&gt;% \n  inner_join(senti)\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., senti): Detected an unexpected many-to-many relationship between `x` and `y`.\n‚Ñπ Row 778 of `x` matches multiple rows in `y`.\n‚Ñπ Row 5008 of `y` matches multiple rows in `x`.\n‚Ñπ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\nZuletzt werden noch die Sentimentwerte aller Posts in einem Jahr zusammengefasst und mit der Anzahl der Posts gewichtet.\n\npostssenti &lt;- poststoken_senti %&gt;% \n  mutate(year = year(timestamp)) %&gt;%\n  group_by(year) %&gt;%\n  summarize(value = mean(value),\n            postcount = length(unique((timestamp)))) %&gt;% \n  mutate(sentiment = (value * postcount) / sum(postcount))\n\nnrow(postssenti)\n\n[1] 9\n\n\n\ncommssenti &lt;- commstoken_senti %&gt;%\n  mutate(year = year(timestamp)) %&gt;% \n  group_by(year) %&gt;% \n  summarize(value = mean(value),\n            postcount = length(unique((timestamp)))) %&gt;% \n  mutate(sentiment = (value * postcount) / sum(postcount))\nnrow(commssenti)\n\n[1] 10\n\n\n\npostssenti %&gt;% \n  ggplot(aes(year, sentiment)) + \n  geom_line(linewidth = 1, colour = \"#6fb899\") +\n  labs(title = \"Sentimentwerte der Posts im Zeitverlauf\",\n       x = \"Jahr\",\n       y = \"Sentiment\") +\n  theme_minimal()\n\n\n\n\n\ncommssenti %&gt;% \n  ggplot(aes(year, sentiment)) + \n  geom_line(linewidth = 1, colour = \"#6fb899\") +\n  scale_x_continuous(breaks = 2013:2024)+\n  labs(title = \"Sentimentwerte der Kommentare im Zeitverlauf\",\n       x = \"Jahr\",\n       y = \"Sentiment\") +\n  theme_minimal()\n\n\n\n\nDie Sentimentwerte im Zeitverlauf sind √ºberaus interessant. Auch wenn der Sentimentwert um den Nullbereich liegt, denke ich dennoch, dass er eine gewisse Aussagekraft hat. Gerade wenn er im Jahr 2022 sowohl bei den Posts als auch bei den Kommentaren rapide einbricht, um seinen absoluten Tiefpunkt zu erreichen, sollte man genauer hinsehen. Im Jahr 2022 stand es um die √∂ffentliche Meinung zu Kanye West so schlecht wie noch nie zuvor. Durch st√§ndige antisemitische √Ñu√üerungen, das Posten eines Hakenkreuzes und Tragen eines ‚ÄúWhite Lifes Matter‚Äù-Hoodies erreichte er die Sperrung seiner Social Media Accounts, die K√ºndigung der Kooperation mit Adidas und die Ausl√∂sung eines Shit-Storms in den sozialen Medien. Dieser Zusammenhang k√∂nnte obige Diagramme erkl√§ren.\n\n\n\n\npoststoken_senti %&gt;%\n  count(word, neg_pos, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  group_by(neg_pos) %&gt;%\n  slice_max(n, n = 10)%&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot(aes(n, word, fill = neg_pos)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~neg_pos, scales = \"free_y\") +\n  labs(x = \"H√§ufigkeit\",\n       y = \"Wort\") +\n  theme_minimal() +\n  scale_fill_tableau(palette = \"Nuriel Stone\")\n\n\n\n\nDie h√§ufigsten positiven W√∂rter sind insofern interessant, als sie den Themen des christlichen Glaubens widerspiegeln. Denn Kanye West bekennt sich regelm√§√üig in Interviews und Tweets zum Christentum. Inwiefern seine antisemitschen √Ñu√üerungen mit diesem Glauben vereinbar sind, sei mal dahingestellt.\n\ncomms_bigram &lt;- \n  all_comments %&gt;%\n  unnest_tokens(bigram, comment, token = \"ngrams\", n = 2) %&gt;%\n  filter(!is.na(bigram))\n\ncomms_bigram &lt;- comms_bigram %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")%&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\ncomms_bigram %&gt;%\n  unite(bigram, word1, word2, sep = \" \") %&gt;%\n  count(bigram, sort = TRUE) %&gt;%\n  slice_max(n, n = 10)%&gt;%\n  mutate(bigram = reorder(bigram, n)) %&gt;%\n  ggplot(aes(n, bigram)) +\n  geom_col(fill = \"#8175aa\") +\n  labs(title = \"Bigramme nach H√§ufigkeit\",\n       x = \"H√§ufigkeit\",\n       y = \"Bigram\") +\n  theme_minimal()\n\n\n\n\nInteressant ist bei der Betrachtung der h√§ufigsten Bigramme, die in den Kommentaren vorkommen, wie pr√§sent das Thema der psychischen St√∂rungen ist. Die Mutma√üung, dass in den Kommentaren √ºber Kanye Wests mentale Gesundheit diskutiert wird, ist nicht unplausibel.\n\n\n\n\nposts_dtm2 &lt;- commstoken_senti %&gt;% \n  mutate(timestamp = as_datetime(timestamp),\n         year = year(timestamp)) %&gt;% \n  filter(year == 2022) %&gt;%\n  select(word) %&gt;% \n  DocumentTermMatrix(commstoken_senti)\n\nWarning: Unknown or uninitialised column: `tokenize`.\n\n\nWarning: Unknown or uninitialised column: `tolower`.\n\n\nWarning: Unknown or uninitialised column: `stopwords`.\nUnknown or uninitialised column: `stopwords`.\n\n\nWarning: Unknown or uninitialised column: `dictionary`.\n\n\nWarning: Unknown or uninitialised column: `bounds`.\n\n\nWarning: Unknown or uninitialised column: `wordLengths`.\n\n\nWarning: Unknown or uninitialised column: `removePunctuation`.\n\n\nWarning: Unknown or uninitialised column: `removeNumbers`.\n\n\nWarning: Unknown or uninitialised column: `stemming`.\n\n\nWarning: Unknown or uninitialised column: `bounds`.\n\n\nWarning: Unknown or uninitialised column: `weighting`.\n\nposts_lda2 &lt;- LDA(posts_dtm2, k = 4, control = list(seed = 42))\n\nposts_themen2 &lt;- tidy(posts_lda2, matrix = \"beta\")\n\nposts_themen2 &lt;- posts_themen2 %&gt;%\n  group_by(topic) %&gt;%\n  slice_max(beta, n = 7) %&gt;% \n  ungroup() %&gt;%\n  arrange(topic, -beta)\n\nposts_themen2 %&gt;%\n  mutate(term = reorder_within(term, beta, topic)) %&gt;%\n  ggplot(aes(beta, term, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ topic, scales = \"free\") +\n  scale_y_reordered() +\n  labs(title = \"Kommentarthemen in 2022 \") +\n  theme_minimal() +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\nDie Analyse der Kommentarthemen des Jahres 2022 deuten ebenfalls auf Kanye Wests √Ñu√üerungen hin, da im ersten Thema dem Wort ‚Äúhitler‚Äù eine gewisse Bedeutung zugeordnet wird."
  },
  {
    "objectID": "posts/Hate Speech auf Reddit/Hatespeech_Reddit.html#klassifikation-von-hate-speech",
    "href": "posts/Hate Speech auf Reddit/Hatespeech_Reddit.html#klassifikation-von-hate-speech",
    "title": "Hate Speech auf Reddit",
    "section": "",
    "text": "Gerade in Zusammenhang mit konktroversen Themen und Personen ist die Analyse von Hate Speech in den sozialen Medien relevant. In Bezug auf die Kommentare zu Kanye West Posts ist es denke ich sehr interessant zu sehen, welcher Anteil der Kommentare als Hate Speech gilt. F√ºr die Vorhersage wende ich Zero-Shot-Klassifikation mit Hilfe des vortrainierten Large Language Modells LFTW R4 Target von facebook an, welches ich √ºber das Modul transformers von Huggingface anspreche, an.\n\n\nZun√§chst lade ich alle erforderlichen Module sowie das Modell. Der Code zur Verwendung des pipeline-Befehls wird hilfreicherweise von Huggingface bereitgestellt.\n\nlibrary(reticulate)\n\nWarning: package 'reticulate' was built under R version 4.2.3\n\nuse_virtualenv(\"C:/Users/rapha/venv\")\n\n\nimport pandas as pd\nimport tensorflow as tf\n\nWARNING:tensorflow:From C:\\Users\\rapha\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\nfrom transformers import pipeline\n\nclassifier = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\")\n\nWARNING:tensorflow:From C:\\Users\\rapha\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n\n\n\n\n\nF√ºr die Klassifikation von Hate-Speech ziehe ich aus allen Kommentaren eine zuf√§llige Stichprobe, da RoBERTa nur eine Maximall√§nge von 513 Inputs akzeptiert.\n\nset.seed(123)\ncomments_sample &lt;- all_comments %&gt;%\n  sample_n(size = 513, replace = FALSE)\n\ncomments_short &lt;- comments_sample$comment\n\nNun lade ich die Kommentare der Stichprobe in das Modell.\n\ncomments = r.comments_short\nresult = classifier(comments)\n\nAnschlie√üend f√ºge ich der Stichprobe das Ergebnis der Klassifikation als neue Spalte hinzu.\n\nresult &lt;- py$result\nlabels &lt;- lapply(result, function(element) element$label)\ncomments_hate &lt;- cbind(comments_sample, hatespeech = unlist(labels)) %&gt;%\n  select(timestamp, comment, hatespeech, comment_id, url)\n\n\n\n\nIm Folgenden untersuche ich die als Hate Speech klassifizierten Kommentare etwas n√§her, indem ich den Anteil der Hate Speech im Jahresverlauf sowie den Zusammenhang mit negativem Sentiment betrachte.\n\ncomments_hate %&gt;%\n   count(hatespeech == \"hate\")\n\n\n\n  \n\n\n\n\ncomments_hate %&gt;%\n  mutate(timestamp = as_datetime(timestamp, origin = \"1970-01-01\"),\n         year = year(timestamp)) %&gt;%\n  group_by(year, hatespeech) %&gt;%\n  count() %&gt;%\n  ggplot(aes(x = year, y = n, fill = hatespeech)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Hatespeech-Kommentare im Zeitverlauf\",\n       x = \"Jahr\",\n       y = \"Anzahl\",\n       fill = \"Hate Speech\") +\n  scale_fill_tableau(\"Nuriel Stone\") +\n  theme_minimal()\n\n\n\n\nAuch wenn nur ein winziger Teil der Kommentare als Hate Speech klassifiziert wurde, ist in diesem Diagramm erkennbar, dass wieder im Jahr 2022 mit Abstand die meiste Hassrede auftrat.\n\ncommstokensenti_hate &lt;- comments_hate %&gt;% \n  filter(hatespeech == \"hate\") %&gt;% \n  unnest_tokens(word, comment) %&gt;% \n  inner_join(senti)\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., senti): Detected an unexpected many-to-many relationship between `x` and `y`.\n‚Ñπ Row 541 of `x` matches multiple rows in `y`.\n‚Ñπ Row 4906 of `y` matches multiple rows in `x`.\n‚Ñπ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ncommstokensenti_hate %&gt;% \n  summarise(mean(neg_pos == \"neg\"))\n\n\n\n  \n\n\n\n\ncomments_hate %&gt;% \n  filter(hatespeech == \"hate\") %&gt;% \n  select(comment)\n\n\n\n  \n\n\n\nNur die H√§lfte der als Hassrede klassifizierten Kommentare haben ein negatives Sentiment. Au√üerdem halte ich pers√∂nlich S√§tze wie ‚ÄúYou are an old one.‚Äù nicht f√ºr Hate Speech. In Kombination mit dem Fakt, dass nur 34 von 513 Tweets als Hate Speech erkannt wurden, lassen mich diese Ergebnisse vermuten, dass das Modell nicht allzu zuverl√§ssige Vorhersagen macht."
  },
  {
    "objectID": "posts/Hate Speech auf Reddit/Hatespeech_Reddit.html#fazit",
    "href": "posts/Hate Speech auf Reddit/Hatespeech_Reddit.html#fazit",
    "title": "Hate Speech auf Reddit",
    "section": "",
    "text": "Es l√§sst sich sagen, dass die Analyse durchaus interessante Erkenntnisse hervorgebracht hat. Die Sentimentwerte k√∂nnen in einen klaren Zusammenhang mit dem Verhalten Kanye Wests gesetzt werden. Allerdings unterliegen diese Erkenntnisse starken Limitationen. Zum einen ist die Anzahl der verwertbaren Posts verschwindend gering, was die Aussagekraft der Analyse dieser beeintr√§chtigt. Deshalb lag das Augenmerk auch st√§rker auf den Kommentaren. Die Schwankungen in den Sentimentwerten beeintr√§chtigen ebenfalls die Aussagekraft der gewonnenen Erkenntnisse, da diese infinitesimal klein ausfallen. Die Klassifikationen des RoBERTa-Modells halte ich ebenfalls f√ºr stark ausbauf√§hig. Es w√§re sinnvoll, in weiteren Analysen noch andere Large Language Modelle f√ºr diese Aufgabe auszuprobieren. Ziel der Analyse war es jedoch auch, zu sehen, ob Redditposts √§hnlich interessant f√ºr die Analyse von Social-Media-Foren sind wie Tweets. Diese Frage ist auf jeden Fall mit Ja zu beantworten, zum einen aufgrund der leichten Zug√§nglichkeit und zum anderen aufgrund des regen Themenaustausches in den Threads, wie er hier beobachtet wurde."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Hate Speech auf Reddit\n\n\n\n\n\n\n\nTextanalyse\n\n\nKlassifikation\n\n\nHuggingface\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2024\n\n\nRaphael Balzer\n\n\n\n\n\n\n  \n\n\n\n\nHatespeech Klassifikation\n\n\n\n\n\n\n\nTextanalyse\n\n\nKlassifikation\n\n\ntidymodels\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2023\n\n\nRaphael Balzer\n\n\n\n\n\n\n  \n\n\n\n\nMini-Textanalyse DS\n\n\n\n\n\n\n\nText-Analyse\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2023\n\n\nRaphael Balzer\n\n\n\n\n\n\n  \n\n\n\n\nbikeshare python\n\n\n\n\n\n\n\nEDA\n\n\nRegression\n\n\npython\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2023\n\n\nRaphael Balzer\n\n\n\n\n\n\n  \n\n\n\n\nbikeshare prediction\n\n\n\n\n\n\n\nEDA\n\n\nRegression\n\n\ntidymodels\n\n\n\n\n\n\n\n\n\n\n\nAug 16, 2023\n\n\nRaphael Balzer\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Hatespeech germeval/germeval.html",
    "href": "posts/Hatespeech germeval/germeval.html",
    "title": "Hatespeech Klassifikation",
    "section": "",
    "text": "Klassifikation von Hatespeech auf Grundlage der Germeval-Daten.\n\n\n\n\n\nlibrary(tidymodels)\nlibrary(textrecipes)\nlibrary(syuzhet)\nlibrary(stringr)\nlibrary(slider)\nlibrary(tidytext)\nlibrary(furrr)\nlibrary(widyr)\nlibrary(irlba)\nlibrary(datawizard)\nlibrary(lightgbm)\nlibrary(bonsai)\nlibrary(vip)\ndata(\"schimpfwoerter\", package = \"pradadata\")\ndata(\"sentiws\", package = \"pradadata\")\ndata(wild_emojis, package = \"pradadata\")\n\n\n\n\nBei den Daten handelt es sich um die Trainings- und Testdaten (deutsche Tweets) aus der GermEval 2018 Shared Task zum Erkennen von beleidigender Sprache.\n\nd_train &lt;- \n  data_read(\"germeval2018.training.txt\",\n         header = FALSE,\n         quote = \"\")\nd_test &lt;- \n  data_read(\"germeval2018.test.txt\",\n         header = FALSE,\n         quote = \"\")\nnames(d_train) &lt;- c(\"text\", \"c1\", \"c2\")\nnames(d_test) &lt;- c(\"text\", \"c1\", \"c2\")\n\n\n\n\n\nZiel ist es, auf Grundlage der Tweets einige n√ºtzliche Features zu generieren, die sich als Pr√§diktor f√ºr die AV (Hatespeech oder nicht) eignen.\nDa das Attribut lexicon Funktion get_sentiment ein Dataframe mit mindestens zwei Spalten mit dem Namen ‚Äúword‚Äù und ‚Äúvalue‚Äù haben muss, f√ºge ich die Spalte ‚Äúvalue‚Äù zum Schimpfw√∂rterlexikon hinzu, um W√∂rter als Schimpfwort zu kennzeichnen.\n\nschimpfwoerter$value &lt;- 1\n\n\n\nUm ‚Äúwilde‚Äù Emojis zu kennzeichnen, verwende ich ein Lexikon, das solche Emojis enth√§lt und schreibe eine Funktion, die z√§hlt, wieviele wilde Emojis in einem Tweet vorkommen.\n\ncount_wild_emojis &lt;- function(text) {\n  # Initialisiere einen leeren Vektor f√ºr die Z√§hlungen\n  counts &lt;- numeric(length(wild_emojis$emoji))\n\n  # Iteriere √ºber jedes Emoji und z√§hle die √úbereinstimmungen im Text\n  for (i in seq_along(wild_emojis$emoji)) {\n    counts[i] &lt;- sum(lengths(str_extract_all(text, wild_emojis$emoji[i])))\n  }\n\n  # Summiere die Gesamtanzahl der √úbereinstimmungen\n  total_count &lt;- sum(counts)\n  return(total_count)\n}\n\ndummy &lt;- c(\"üóë\", \"bogen\", \"üò†\", \"üëπ\", \"üí©\", \"baby\", \"und\", \"üÜó\")\ncount_wild_emojis(dummy)\n\n[1] 4\n\n\n\n\n\n\nnested_words &lt;- d_train %&gt;%\n  select(text) %&gt;% \n  unnest_tokens(word, text) %&gt;%\n  nest(words = c(word))\n\nSkipgrams identifizieren:\n\nslide_windows &lt;- function(tbl, window_size) {\n  skipgrams &lt;- slider::slide(\n    tbl, \n    ~.x, \n    .after = window_size - 1, \n    .step = 1, \n    .complete = TRUE\n  )\n  \n  safe_mutate &lt;- safely(mutate)\n  \n  out &lt;- map2(skipgrams,\n              1:length(skipgrams),\n              ~ safe_mutate(.x, window_id = .y))\n  \n  out %&gt;%\n    transpose() %&gt;%\n    pluck(\"result\") %&gt;%\n    compact() %&gt;%\n    bind_rows()\n}\n\nPMI berechnen:\n\ntidy_pmi &lt;- nested_words %&gt;%\n  mutate(words = future_map(words, slide_windows, 4L)) %&gt;%\n  unnest(words) %&gt;%\n  pairwise_pmi(word, window_id)\ntidy_pmi\n\n\n\n  \n\n\n\nWortvektoren erstellen:\n\ntidy_word_vectors &lt;- tidy_pmi %&gt;%\n  widely_svd(\n    item1, item2, pmi,\n    nv = 100, maxit = 1000\n  )\n\ntidy_word_vectors\n\n\n\n  \n\n\n\n\n\n\n\n\n\nRezept 1 enth√§lt Schimpfw√∂rter, Sentimentwerte, aggressive Emojis und Word Embeddings\n\nrec1 &lt;-\n  recipe(c1 ~ ., data = d_train) %&gt;% \n  update_role(c2, new_role = \"ignore\") %&gt;%  \n  step_text_normalization(text) %&gt;%\n  step_mutate(schimpfw = get_sentiment(text,\n                                       method = \"custom\",\n                                       lexicon = schimpfwoerter)) %&gt;% \n  step_mutate(senti = get_sentiment(text,\n                                    method = \"custom\",\n                                    lexicon = sentiws)) %&gt;%\n  step_mutate(wild_emojis_n = map_int(text, \n                                      count_wild_emojis)) %&gt;% \n  step_tokenize(text, token = \"words\") %&gt;% \n  step_stem(text) %&gt;% \n  step_tokenfilter(text, max_tokens = 1e2) %&gt;%\n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %&gt;% \n  step_word_embeddings(text,\n                       embeddings = tidy_word_vectors,\n                       aggregation = \"mean\")\n\nRezept 2 enth√§lt statt Word-Embeddings tfidf.\n\nrec2 &lt;-\n  recipe(c1 ~ ., data = d_train) %&gt;% \n  update_role(c2, new_role = \"ignore\") %&gt;%  \n  step_text_normalization(text) %&gt;%\n  step_mutate(schimpfw = get_sentiment(text,\n                                       method = \"custom\",\n                                       lexicon = schimpfwoerter)) %&gt;% \n  step_mutate(senti = get_sentiment(text,\n                                    method = \"custom\",\n                                    lexicon = sentiws)) %&gt;%\n  step_mutate(wild_emojis_n = map_int(text, \n                                      count_wild_emojis)) %&gt;% \n  step_tokenize(text, token = \"words\") %&gt;% \n  step_stem(text) %&gt;% \n  step_tokenfilter(text, max_tokens = 1e2) %&gt;%\n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %&gt;% \n  step_tfidf(text)\n\n\nbaked &lt;- rec1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\nbaked\n\n\n\n  \n\n\n\n\nbaked2 &lt;- rec1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\nbaked2\n\n\n\n  \n\n\n\n\n\n\nIch verwende f√ºr die Modellierung zum einen einen K-Nearest-Neighbour-Algorithums und zum anderen XGBoost.\n\nknn &lt;- \n  nearest_neighbor(\n  neighbors = tune(),\n  weight_func = tune(),\n  dist_power = tune()\n) %&gt;% \n  set_engine(\"kknn\") %&gt;% \n  set_mode(\"classification\") %&gt;% \n  translate()\n\nWarning: package 'kknn' was built under R version 4.2.3\n\nxgb &lt;- \n  boost_tree(\n  mtry = tune(), \n  trees = tune(), \n  tree_depth = tune(), \n  learn_rate = tune(), \n  min_n = tune(), \n  loss_reduction = tune()\n  ) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\") %&gt;%\n  translate()\n\n\n\n\n\npreproc &lt;- list(rec1 = rec1, rec2 = rec2)\n\nmodels &lt;- list(xgb = xgb, knn = knn)\n\nall_workflows &lt;- workflow_set(preproc, models)\n\nmodel_set &lt;-\nall_workflows %&gt;%\nworkflow_map(\n  resamples = vfold_cv(d_train,\n  v = 2, \n  repeats = 1),\n  grid = 5,\n  seed = 42,\n  verbose = TRUE)\n\ni 1 of 4 tuning:     rec1_xgb\n\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\nWarning: package 'SnowballC' was built under R version 4.2.3\n\n\nWarning: package 'stopwords' was built under R version 4.2.3\n\n\nWarning: package 'xgboost' was built under R version 4.2.3\n\n\n‚úî 1 of 4 tuning:     rec1_xgb (3m 0.8s)\n\n\ni 2 of 4 tuning:     rec1_knn\n\n\n‚úî 2 of 4 tuning:     rec1_knn (3m 19.2s)\n\n\ni 3 of 4 tuning:     rec2_xgb\n\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n‚úî 3 of 4 tuning:     rec2_xgb (4m 35.7s)\n\n\ni 4 of 4 tuning:     rec2_knn\n\n\n‚úî 4 of 4 tuning:     rec2_knn (3m 56.9s)\n\n\n\n\n\n\ntune::autoplot(model_set) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nmodel_set %&gt;% \n  collect_metrics() %&gt;% \n  arrange(-mean)\n\n\n\n  \n\n\n\nLightGBM hat deutlich besser abgeschnitten als KNN. W√§hlen wir nun das beste Modell aus und fitten es:\n\n\n\n\nbest_model_params &lt;- \n  extract_workflow_set_result(model_set, \"rec1_xgb\") %&gt;% \n  select_best()\n\nWarning: No value of `metric` was given; metric 'roc_auc' will be used.\n\n\n\nbest_wf &lt;- \nall_workflows %&gt;% \n  extract_workflow(\"rec1_xgb\")\n\nbest_wf_finalized &lt;- \n  best_wf %&gt;% \n  finalize_workflow(best_model_params)\n\nfit_final &lt;- fit(best_wf_finalized, data = d_train)\n\n\nfit_final %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip() \n\n\n\n\n\n\n\n\n\npreds &lt;- predict(fit_final, d_test)\npreds\n\n\n\n  \n\n\n\n\n\n\nd_test &lt;-\n  d_test %&gt;%  \n   bind_cols(preds) %&gt;% \n  mutate(c1 = as.factor(c1))\nd_test\n\n\n\n  \n\n\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  },
  {
    "objectID": "posts/Hatespeech germeval/germeval.html#vorbereitung",
    "href": "posts/Hatespeech germeval/germeval.html#vorbereitung",
    "title": "Hatespeech Klassifikation",
    "section": "",
    "text": "library(tidymodels)\nlibrary(textrecipes)\nlibrary(syuzhet)\nlibrary(stringr)\nlibrary(slider)\nlibrary(tidytext)\nlibrary(furrr)\nlibrary(widyr)\nlibrary(irlba)\nlibrary(datawizard)\nlibrary(lightgbm)\nlibrary(bonsai)\nlibrary(vip)\ndata(\"schimpfwoerter\", package = \"pradadata\")\ndata(\"sentiws\", package = \"pradadata\")\ndata(wild_emojis, package = \"pradadata\")\n\n\n\n\nBei den Daten handelt es sich um die Trainings- und Testdaten (deutsche Tweets) aus der GermEval 2018 Shared Task zum Erkennen von beleidigender Sprache.\n\nd_train &lt;- \n  data_read(\"germeval2018.training.txt\",\n         header = FALSE,\n         quote = \"\")\nd_test &lt;- \n  data_read(\"germeval2018.test.txt\",\n         header = FALSE,\n         quote = \"\")\nnames(d_train) &lt;- c(\"text\", \"c1\", \"c2\")\nnames(d_test) &lt;- c(\"text\", \"c1\", \"c2\")"
  },
  {
    "objectID": "posts/Hatespeech germeval/germeval.html#feature-engineering",
    "href": "posts/Hatespeech germeval/germeval.html#feature-engineering",
    "title": "Hatespeech Klassifikation",
    "section": "",
    "text": "Ziel ist es, auf Grundlage der Tweets einige n√ºtzliche Features zu generieren, die sich als Pr√§diktor f√ºr die AV (Hatespeech oder nicht) eignen.\nDa das Attribut lexicon Funktion get_sentiment ein Dataframe mit mindestens zwei Spalten mit dem Namen ‚Äúword‚Äù und ‚Äúvalue‚Äù haben muss, f√ºge ich die Spalte ‚Äúvalue‚Äù zum Schimpfw√∂rterlexikon hinzu, um W√∂rter als Schimpfwort zu kennzeichnen.\n\nschimpfwoerter$value &lt;- 1\n\n\n\nUm ‚Äúwilde‚Äù Emojis zu kennzeichnen, verwende ich ein Lexikon, das solche Emojis enth√§lt und schreibe eine Funktion, die z√§hlt, wieviele wilde Emojis in einem Tweet vorkommen.\n\ncount_wild_emojis &lt;- function(text) {\n  # Initialisiere einen leeren Vektor f√ºr die Z√§hlungen\n  counts &lt;- numeric(length(wild_emojis$emoji))\n\n  # Iteriere √ºber jedes Emoji und z√§hle die √úbereinstimmungen im Text\n  for (i in seq_along(wild_emojis$emoji)) {\n    counts[i] &lt;- sum(lengths(str_extract_all(text, wild_emojis$emoji[i])))\n  }\n\n  # Summiere die Gesamtanzahl der √úbereinstimmungen\n  total_count &lt;- sum(counts)\n  return(total_count)\n}\n\ndummy &lt;- c(\"üóë\", \"bogen\", \"üò†\", \"üëπ\", \"üí©\", \"baby\", \"und\", \"üÜó\")\ncount_wild_emojis(dummy)\n\n[1] 4\n\n\n\n\n\n\nnested_words &lt;- d_train %&gt;%\n  select(text) %&gt;% \n  unnest_tokens(word, text) %&gt;%\n  nest(words = c(word))\n\nSkipgrams identifizieren:\n\nslide_windows &lt;- function(tbl, window_size) {\n  skipgrams &lt;- slider::slide(\n    tbl, \n    ~.x, \n    .after = window_size - 1, \n    .step = 1, \n    .complete = TRUE\n  )\n  \n  safe_mutate &lt;- safely(mutate)\n  \n  out &lt;- map2(skipgrams,\n              1:length(skipgrams),\n              ~ safe_mutate(.x, window_id = .y))\n  \n  out %&gt;%\n    transpose() %&gt;%\n    pluck(\"result\") %&gt;%\n    compact() %&gt;%\n    bind_rows()\n}\n\nPMI berechnen:\n\ntidy_pmi &lt;- nested_words %&gt;%\n  mutate(words = future_map(words, slide_windows, 4L)) %&gt;%\n  unnest(words) %&gt;%\n  pairwise_pmi(word, window_id)\ntidy_pmi\n\n\n\n  \n\n\n\nWortvektoren erstellen:\n\ntidy_word_vectors &lt;- tidy_pmi %&gt;%\n  widely_svd(\n    item1, item2, pmi,\n    nv = 100, maxit = 1000\n  )\n\ntidy_word_vectors"
  },
  {
    "objectID": "posts/Hatespeech germeval/germeval.html#modellierung",
    "href": "posts/Hatespeech germeval/germeval.html#modellierung",
    "title": "Hatespeech Klassifikation",
    "section": "",
    "text": "Rezept 1 enth√§lt Schimpfw√∂rter, Sentimentwerte, aggressive Emojis und Word Embeddings\n\nrec1 &lt;-\n  recipe(c1 ~ ., data = d_train) %&gt;% \n  update_role(c2, new_role = \"ignore\") %&gt;%  \n  step_text_normalization(text) %&gt;%\n  step_mutate(schimpfw = get_sentiment(text,\n                                       method = \"custom\",\n                                       lexicon = schimpfwoerter)) %&gt;% \n  step_mutate(senti = get_sentiment(text,\n                                    method = \"custom\",\n                                    lexicon = sentiws)) %&gt;%\n  step_mutate(wild_emojis_n = map_int(text, \n                                      count_wild_emojis)) %&gt;% \n  step_tokenize(text, token = \"words\") %&gt;% \n  step_stem(text) %&gt;% \n  step_tokenfilter(text, max_tokens = 1e2) %&gt;%\n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %&gt;% \n  step_word_embeddings(text,\n                       embeddings = tidy_word_vectors,\n                       aggregation = \"mean\")\n\nRezept 2 enth√§lt statt Word-Embeddings tfidf.\n\nrec2 &lt;-\n  recipe(c1 ~ ., data = d_train) %&gt;% \n  update_role(c2, new_role = \"ignore\") %&gt;%  \n  step_text_normalization(text) %&gt;%\n  step_mutate(schimpfw = get_sentiment(text,\n                                       method = \"custom\",\n                                       lexicon = schimpfwoerter)) %&gt;% \n  step_mutate(senti = get_sentiment(text,\n                                    method = \"custom\",\n                                    lexicon = sentiws)) %&gt;%\n  step_mutate(wild_emojis_n = map_int(text, \n                                      count_wild_emojis)) %&gt;% \n  step_tokenize(text, token = \"words\") %&gt;% \n  step_stem(text) %&gt;% \n  step_tokenfilter(text, max_tokens = 1e2) %&gt;%\n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %&gt;% \n  step_tfidf(text)\n\n\nbaked &lt;- rec1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\nbaked\n\n\n\n  \n\n\n\n\nbaked2 &lt;- rec1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\nbaked2\n\n\n\n  \n\n\n\n\n\n\nIch verwende f√ºr die Modellierung zum einen einen K-Nearest-Neighbour-Algorithums und zum anderen XGBoost.\n\nknn &lt;- \n  nearest_neighbor(\n  neighbors = tune(),\n  weight_func = tune(),\n  dist_power = tune()\n) %&gt;% \n  set_engine(\"kknn\") %&gt;% \n  set_mode(\"classification\") %&gt;% \n  translate()\n\nWarning: package 'kknn' was built under R version 4.2.3\n\nxgb &lt;- \n  boost_tree(\n  mtry = tune(), \n  trees = tune(), \n  tree_depth = tune(), \n  learn_rate = tune(), \n  min_n = tune(), \n  loss_reduction = tune()\n  ) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\") %&gt;%\n  translate()\n\n\n\n\n\npreproc &lt;- list(rec1 = rec1, rec2 = rec2)\n\nmodels &lt;- list(xgb = xgb, knn = knn)\n\nall_workflows &lt;- workflow_set(preproc, models)\n\nmodel_set &lt;-\nall_workflows %&gt;%\nworkflow_map(\n  resamples = vfold_cv(d_train,\n  v = 2, \n  repeats = 1),\n  grid = 5,\n  seed = 42,\n  verbose = TRUE)\n\ni 1 of 4 tuning:     rec1_xgb\n\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\nWarning: package 'SnowballC' was built under R version 4.2.3\n\n\nWarning: package 'stopwords' was built under R version 4.2.3\n\n\nWarning: package 'xgboost' was built under R version 4.2.3\n\n\n‚úî 1 of 4 tuning:     rec1_xgb (3m 0.8s)\n\n\ni 2 of 4 tuning:     rec1_knn\n\n\n‚úî 2 of 4 tuning:     rec1_knn (3m 19.2s)\n\n\ni 3 of 4 tuning:     rec2_xgb\n\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n‚úî 3 of 4 tuning:     rec2_xgb (4m 35.7s)\n\n\ni 4 of 4 tuning:     rec2_knn\n\n\n‚úî 4 of 4 tuning:     rec2_knn (3m 56.9s)\n\n\n\n\n\n\ntune::autoplot(model_set) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nmodel_set %&gt;% \n  collect_metrics() %&gt;% \n  arrange(-mean)\n\n\n\n  \n\n\n\nLightGBM hat deutlich besser abgeschnitten als KNN. W√§hlen wir nun das beste Modell aus und fitten es:\n\n\n\n\nbest_model_params &lt;- \n  extract_workflow_set_result(model_set, \"rec1_xgb\") %&gt;% \n  select_best()\n\nWarning: No value of `metric` was given; metric 'roc_auc' will be used.\n\n\n\nbest_wf &lt;- \nall_workflows %&gt;% \n  extract_workflow(\"rec1_xgb\")\n\nbest_wf_finalized &lt;- \n  best_wf %&gt;% \n  finalize_workflow(best_model_params)\n\nfit_final &lt;- fit(best_wf_finalized, data = d_train)\n\n\nfit_final %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()"
  },
  {
    "objectID": "posts/Hatespeech germeval/germeval.html#vorhersagen",
    "href": "posts/Hatespeech germeval/germeval.html#vorhersagen",
    "title": "Hatespeech Klassifikation",
    "section": "",
    "text": "preds &lt;- predict(fit_final, d_test)\npreds\n\n\n\n  \n\n\n\n\n\n\nd_test &lt;-\n  d_test %&gt;%  \n   bind_cols(preds) %&gt;% \n  mutate(c1 = as.factor(c1))\nd_test\n\n\n\n  \n\n\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)"
  }
]