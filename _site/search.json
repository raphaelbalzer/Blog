[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Dieser persönliche Blog dient als Sammlung für sämtliche Data-Science Projekte in Zusammenhang mit dem Studium und Selbststudium."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Mini-Textanalyse DS\n\n\n\n\n\n\n\nText-Analyse\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2023\n\n\nRaphael Balzer\n\n\n\n\n\n\n  \n\n\n\n\nbikeshare python\n\n\n\n\n\n\n\nEDA\n\n\nRegression\n\n\npython\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2023\n\n\nRaphael Balzer\n\n\n\n\n\n\n  \n\n\n\n\nbikeshare prediction\n\n\n\n\n\n\n\nEDA\n\n\nRegression\n\n\ntidymodels\n\n\n\n\n\n\n\n\n\n\n\nAug 16, 2023\n\n\nRaphael Balzer\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Bikeshare Analyse/bikeshare.html",
    "href": "posts/Bikeshare Analyse/bikeshare.html",
    "title": "bikeshare prediction",
    "section": "",
    "text": "Im Folgenden sollen Fahrradausleihungen vorhergesagt werden. Gegenstand der Analysen ist ein Datensatz, der unter anderem Wetterdaten, Auskunft über das Datum und die Uhrzeit und die Anzahl der täglich geliehenen Fahrräder zu jeder Stunde enthält. Zunächst soll ein Überblick über den Datensatz und die Wechselwirkungen der Variablen untereinander verschafft werden. Im zweiten Teil werden Modelle mit einigen Vorverarbeitungsschritten trainiert, um dann im letzten Schritt die Vorhersagedatei zu erstellen. Als Framework für die Modellierung wird Tidymodels verwendet.\n\n\n\n\n\nlibrary(ggcorrplot)\n\nLoading required package: ggplot2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.6.0 (red = needs update)\n✔ bayestestR  0.13.1   ✔ correlation 0.8.4 \n✖ datawizard  0.7.1    ✖ effectsize  0.8.3 \n✖ insight     0.19.2   ✔ modelbased  0.8.6 \n✖ performance 0.10.3   ✖ parameters  0.21.1\n✔ report      0.5.7    ✖ see         0.7.5 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.2.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tibble       3.2.1\n✔ dplyr        1.1.2     ✔ tidyr        1.3.0\n✔ infer        1.0.4     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.1     ✔ yardstick    1.2.0\n✔ recipes      1.0.8     \n\n\nWarning: package 'broom' was built under R version 4.2.3\n\n\nWarning: package 'dials' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'modeldata' was built under R version 4.2.3\n\n\nWarning: package 'parsnip' was built under R version 4.2.3\n\n\nWarning: package 'recipes' was built under R version 4.2.3\n\n\nWarning: package 'rsample' was built under R version 4.2.3\n\n\nWarning: package 'tibble' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\nWarning: package 'tune' was built under R version 4.2.3\n\n\nWarning: package 'workflowsets' was built under R version 4.2.3\n\n\nWarning: package 'yardstick' was built under R version 4.2.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()         masks scales::discard()\n✖ dplyr::filter()          masks stats::filter()\n✖ yardstick::get_weights() masks insight::get_weights()\n✖ dplyr::lag()             masks stats::lag()\n✖ yardstick::mae()         masks performance::mae()\n✖ parsnip::null_model()    masks insight::null_model()\n✖ infer::p_value()         masks parameters::p_value()\n✖ tune::parameters()       masks dials::parameters(), parameters::parameters()\n✖ yardstick::rmse()        masks performance::rmse()\n✖ dials::smoothness()      masks datawizard::smoothness()\n✖ recipes::step()          masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ readr   2.1.3     ✔ forcats 1.0.0\n✔ stringr 1.5.0     \n\n\nWarning: package 'forcats' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\n\nlibrary(corrr)\nlibrary(tidytext)\n\nWarning: package 'tidytext' was built under R version 4.2.3\n\nlibrary(ggthemes)\nlibrary(ggplot2)\nlibrary(GGally)\n\nWarning: package 'GGally' was built under R version 4.2.3\n\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nlibrary(lubridate)\n\nWarning: package 'lubridate' was built under R version 4.2.3\n\n\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(xgboost)\n\nWarning: package 'xgboost' was built under R version 4.2.3\n\n\n\nAttaching package: 'xgboost'\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\nlibrary(Cubist)\n\nWarning: package 'Cubist' was built under R version 4.2.3\n\n\nLoading required package: lattice\n\nlibrary(rules)\n\nWarning: package 'rules' was built under R version 4.2.3\n\n\n\nAttaching package: 'rules'\n\nThe following object is masked from 'package:dials':\n\n    max_rules\n\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.2.3\n\n\n\nAttaching package: 'caret'\n\nThe following objects are masked from 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nThe following object is masked from 'package:parameters':\n\n    compare_models\n\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.2.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\n\n\n\n\n\nlibrary(readr)\nbikeshare_test &lt;- read_csv(\"bikeshare_test.csv\")\n\nRows: 2192 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): date, season, holiday, func\ndbl (9): hour, temp, humidity, windspeed, visibility, dewpointtemp, solar, r...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nlibrary(readr)\nbikeshare_train &lt;- read_csv(\"bikeshare_train.csv\")\n\nRows: 6568 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): date, season, holiday, func\ndbl (10): count, hour, temp, humidity, windspeed, visibility, dewpointtemp, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbikeshare_train\n\n# A tibble: 6,568 × 14\n   date       count  hour  temp humidity windspeed visibility dewpointtemp solar\n   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 01/12/2017   173     2  -6         39       1         2000        -17.7     0\n 2 01/12/2017   107     3  -6.2       40       0.9       2000        -17.6     0\n 3 01/12/2017    78     4  -6         36       2.3       2000        -18.6     0\n 4 01/12/2017   100     5  -6.4       37       1.5       2000        -18.7     0\n 5 01/12/2017   181     6  -6.6       35       1.3       2000        -19.5     0\n 6 02/12/2017   167     3  -3.5       81       2.2       1221         -6.2     0\n 7 02/12/2017    89     4  -3.8       79       2         1167         -6.9     0\n 8 02/12/2017    70     6  -4.3       82       2.1       1178         -6.9     0\n 9 02/12/2017   146     7  -4.4       81       2.5       1276         -7.1     0\n10 03/12/2017    32     5   3.9       75       1.9        914         -0.1     0\n# ℹ 6,558 more rows\n# ℹ 5 more variables: rain &lt;dbl&gt;, snow &lt;dbl&gt;, season &lt;chr&gt;, holiday &lt;chr&gt;,\n#   func &lt;chr&gt;\n\n\n\n\n\n\n\n\n\nbikeshare_train %&gt;% \n  ggcorr(label = TRUE)\n\nWarning in ggcorr(., label = TRUE): data in column(s) 'date', 'season',\n'holiday', 'func' are not numeric and were ignored\n\n\n\n\n\n\n\n\n\nbikeshare_train %&gt;% \n  summarise((across(everything(),~sum(is.na(.x)))))\n\n# A tibble: 1 × 14\n   date count  hour  temp humidity windspeed visibility dewpointtemp solar  rain\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;     &lt;int&gt;      &lt;int&gt;        &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     0     0     0     0        0         0          0            0     0     0\n# ℹ 4 more variables: snow &lt;int&gt;, season &lt;int&gt;, holiday &lt;int&gt;, func &lt;int&gt;\n\n\n\nbikeshare_test %&gt;%\n  summarise((across(everything(),~sum(is.na(.x)))))\n\n# A tibble: 1 × 13\n   date  hour  temp humidity windspeed visibility dewpointtemp solar  rain  snow\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;     &lt;int&gt;      &lt;int&gt;        &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     0     0     0        0         0          0            0     0     0     0\n# ℹ 3 more variables: season &lt;int&gt;, holiday &lt;int&gt;, func &lt;int&gt;\n\n\n\nvisdat::vis_dat(bikeshare_train)\n\n\n\n\n\n\n\n\nbikeshare_train %&gt;% \n  select(where(is.numeric)) %&gt;% \n  pivot_longer(everything()) %&gt;% \nggplot(., aes(x = value)) +\n  geom_boxplot(fill = \"#4E79A7\") +\n  theme_minimal() +\n  facet_wrap(~ name, scales = \"free_x\")\n\n\n\n\n\nbikeshare_test %&gt;% \n  select(where(is.numeric)) %&gt;% \n  pivot_longer(everything()) %&gt;% \nggplot(., aes(x = value)) +\n  geom_boxplot(fill = \"#4E79A7\") +\n  theme_minimal() +\n  facet_wrap(~ name, scales = \"free_x\")\n\n\n\n\n\n\n\n\nbikeshare_train %&gt;% \n  select(where(is.numeric)) %&gt;% \n  pivot_longer(everything()) %&gt;% \nggplot(., aes(x = value)) +\n  geom_histogram(fill = \"#4E79A7\") +\n  theme_minimal() +\n  facet_wrap(~ name, scales = \"free_x\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nbikeshare_test %&gt;% \n  select(where(is.numeric)) %&gt;% \n  pivot_longer(everything()) %&gt;%  \nggplot(., aes(x = value)) +\n  geom_histogram(fill = \"#4E79A7\") +\n  theme_minimal() +\n  facet_wrap(~ name, scales = \"free_x\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nbikeshare_train %&gt;%\n  pivot_longer(cols = 2:11) %&gt;%  \n  ggplot(., aes(x = value, fill = season)) +\n  geom_boxplot() +\n  facet_wrap(~ name, scales = \"free_x\") +\n  scale_fill_tableau() +\n  theme_minimal()\n\n\n\n\n\nbikeshare_train %&gt;%\n  pivot_longer(cols = 2:11) %&gt;%  \n  ggplot(., aes(x = value, fill = holiday)) +\n  geom_boxplot() +\n  facet_wrap(~ name, scales = \"free_x\") +\n  scale_fill_tableau() +\n  theme_minimal()\n\n\n\n\n\nbikeshare_train %&gt;%\n  pivot_longer(cols = 2:11) %&gt;%  \n  ggplot(., aes(x = value, fill = func)) +\n  geom_boxplot() +\n  facet_wrap(~ name, scales = \"free_x\") +\n  scale_fill_tableau() +\n  theme_minimal()\n\n\n\n\n\nbikeshare_train %&gt;% \n  ggplot(aes(x = season, fill = holiday)) +\n  geom_bar(alpha = 0.8) +\n  coord_flip() +\n  scale_fill_tableau() +\n  theme_minimal()\n\n\n\n\n\nbikeshare_train %&gt;% \n  ggplot(aes(x = season, fill = func)) +\n  geom_bar(alpha = 0.8) +\n  coord_flip() +\n  scale_fill_tableau() +\n  theme_minimal()\n\n\n\n\n\nbikeshare_train %&gt;% \n  mutate(hour = factor(hour)) %&gt;% \n  ggplot()+\n  aes(hour, count, fill = hour) +\n  geom_boxplot(show.legend = FALSE, alpha = 0.8) +\n  scale_fill_viridis_d() +\n  theme_minimal()\n\n\n\n\n\nbikeshare_train %&gt;%  \n  ggplot()+\n  aes(hour, count) +\n  geom_smooth(color = \"#4E79A7\", linewidth = 2 ) +\n  theme_minimal()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\nbikeshare_train %&gt;%  \n  ggplot()+\n  aes(hour, temp) +\n  geom_smooth(color = \"#4E79A7\", linewidth = 2 ) +\n  theme_minimal()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\nbikeshare_train %&gt;%  \n  ggplot()+\n  aes(hour, humidity) +\n  geom_smooth(color = \"#4E79A7\", linewidth = 2 ) +\n  theme_minimal()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\nbikeshare_train %&gt;%  \n  ggplot()+\n  aes(hour, windspeed) +\n  geom_smooth(color = \"#4E79A7\", linewidth = 2 ) +\n  theme_minimal()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\nbikeshare_train %&gt;%  \n  ggplot()+\n  aes(hour, visibility) +\n  geom_smooth(color = \"#4E79A7\", linewidth = 2 ) +\n  theme_minimal()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\nEs gibt keine fehlenden Werte, Extremwerte sind auch äußerst rar. Durch die explorativen Datenanalyse ist deutlich zu erkennen, dass die Ausleihungen nach Jahres- und Uhrzeit stark variieren. Außerdem sind die Ausleihungen an Arbeitstagen höher. Bei nicht funktionalen Tagen finden keine Ausleihungen statt. Diese Beobachtung gilt es für die Vorhersagen im Hinterkopf zu behalten. Außerdem haben die Wettervariablen ihre Hoch- oder Tiefpunkte zu ungefähr derselben Uhrzeit, zu der auch am meisten Fahrräder geliehen werden.\n\n\n\n\n\n\n\nset.seed(42)\n\ntrain_test_split &lt;- initial_split(bikeshare_train, prop = 0.7497717)\nbikeshare_train1 &lt;- training(train_test_split)\nbikeshare_test1 &lt;- testing(train_test_split)\n\n\n\n\nDas Hauptaugenmerk bei den Rezepten liegt auf der Datumsspalte und den Interaktionen. Nach der Umwandlung in ein Datumsformat können mit step_date() einige interessante Features extrahiert werden. Außerdem gibt es einige interessante Interaktionseffekte. Die folgenden zwei Rezepte liefern die besten Vorhersagen und unterscheiden sich nur hinsichtlich der Normalisierung der Prädiktoren:\n\nrec72 &lt;- \n  recipe(count ~., data = bikeshare_train1) %&gt;%\n  step_mutate(date = lubridate::dmy(date)) %&gt;%\n  step_date(date,  features = c(\"dow\", \"doy\", \"week\"), keep_original_cols = FALSE) %&gt;%\n  step_mutate(date_dow = as.numeric(date_dow),\n              date_week = as.numeric(date_week)) %&gt;%\n  step_normalize(all_numeric_predictors(), -c(hour, date_doy, date_dow, date_week)) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_interact(terms = ~starts_with(\"holiday\"):hour, role = \"predictor\") %&gt;% \n  step_interact(terms = ~starts_with(\"holiday\"):humidity, role = \"predictor\") %&gt;%\n  step_interact(terms = ~starts_with(\"holiday\"):rain, role = \"predictor\") %&gt;%\n  step_interact(terms = ~starts_with(\"holiday\"):date_dow, role = \"predictor\") %&gt;% \n  step_interact(terms = ~starts_with(\"func\"):temp, role = \"predictor\") \n\n\nrec81 &lt;- \n  recipe(count ~., data = bikeshare_train1) %&gt;%\n  step_mutate(date = lubridate::dmy(date)) %&gt;%\n  step_date(date,  features = c(\"dow\", \"doy\", \"week\"), keep_original_cols = FALSE) %&gt;%\n  step_mutate(date_dow = as.numeric(date_dow),\n              date_week = as.numeric(date_week)) %&gt;%\n  step_dummy(all_nominal_predictors())%&gt;% \n  step_interact(terms = ~starts_with(\"holiday\"):hour, role = \"predictor\") %&gt;% \n  step_interact(terms = ~starts_with(\"holiday\"):humidity, role = \"predictor\") %&gt;%\n  step_interact(terms = ~starts_with(\"holiday\"):rain, role = \"predictor\") %&gt;%\n  step_interact(terms = ~starts_with(\"holiday\"):date_dow, role = \"predictor\") %&gt;% \n  step_interact(terms = ~starts_with(\"func\"):temp, role = \"predictor\")\n\n\n\n\n\nEs werden zwei starke Modelle berechnet, ein XGboost und ein Cubist. Die Wahl der Modellarten basiert hauptsächlich auf persönlichen Präferenzen. Es wird außerdem fünffache Kreuzvalidierung mit drei Wiederholungen verwendet.\n\ncv_scheme &lt;- vfold_cv(bikeshare_train1,\n  v = 5, \n  repeats = 3)\n\n\ndoParallel::registerDoParallel()\n\n\nmod_tree &lt;-\n  decision_tree(cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune(),\n                mode = \"regression\")\n\n\nmod_xg &lt;- boost_tree(\n  mtry = tune(), \n  trees = tune(), \n  tree_depth = tune(), \n  learn_rate = tune(), \n  min_n = tune(), \n  loss_reduction = tune()) %&gt;%\n  set_engine(\"xgboost\", nthreads = 4) %&gt;%\n  set_mode(\"regression\")\n\n\nmod_cubist &lt;- cubist_rules(\n  committees = tune(),\n  neighbors = tune(),\n  max_rules = tune()) %&gt;%\n  set_engine(\"Cubist\", nthreads = 4) %&gt;%\n  set_mode(\"regression\")\n\n\npreproc &lt;- list(rec81 = rec81, rec72 = rec72)\n\nmodels &lt;- list(cubist = mod_cubist, xgboost = mod_xg)\n\nall_workflows &lt;- workflow_set(preproc, models)\n\nmodel_set &lt;-\nall_workflows %&gt;% \nworkflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n  seed = 42,\n  verbose = TRUE)\n\ni 1 of 4 tuning:     rec81_cubist\n\n\n✔ 1 of 4 tuning:     rec81_cubist (14m 36.8s)\n\n\ni 2 of 4 tuning:     rec81_xgboost\n\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n✔ 2 of 4 tuning:     rec81_xgboost (29m 41s)\n\n\ni 3 of 4 tuning:     rec72_cubist\n\n\n✔ 3 of 4 tuning:     rec72_cubist (19m 50.1s)\n\n\ni 4 of 4 tuning:     rec72_xgboost\n\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n✔ 4 of 4 tuning:     rec72_xgboost (10m 41.3s)\n\n\n\n\n\n\ntune::autoplot(model_set) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nmodel_set %&gt;% \n  collect_metrics() %&gt;% \n  arrange(-mean)\n\n# A tibble: 80 × 9\n   wflow_id      .config    preproc model .metric .estimator  mean     n std_err\n   &lt;chr&gt;         &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n 1 rec81_xgboost Preproces… recipe  boos… rmse    standard    273.    15    2.42\n 2 rec81_xgboost Preproces… recipe  boos… rmse    standard    270.    15    2.74\n 3 rec81_xgboost Preproces… recipe  boos… rmse    standard    267.    15    3.25\n 4 rec72_xgboost Preproces… recipe  boos… rmse    standard    267.    15    2.56\n 5 rec72_xgboost Preproces… recipe  boos… rmse    standard    266.    15    2.68\n 6 rec81_xgboost Preproces… recipe  boos… rmse    standard    249.    15    3.37\n 7 rec72_xgboost Preproces… recipe  boos… rmse    standard    244.    15    2.87\n 8 rec72_xgboost Preproces… recipe  boos… rmse    standard    243.    15    3.22\n 9 rec72_cubist  Preproces… recipe  cubi… rmse    standard    200.    15    3.25\n10 rec81_cubist  Preproces… recipe  cubi… rmse    standard    188.    15    3.16\n# ℹ 70 more rows\n\n\n\nbest_model_params &lt;- \n  extract_workflow_set_result(model_set, \"rec81_cubist\") %&gt;% \n  select_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\nbest_wf &lt;- \nall_workflows %&gt;% \n  extract_workflow(\"rec81_cubist\")\n\nbest_wf_finalized &lt;- \n  best_wf %&gt;% \n  finalize_workflow(best_model_params)\n\nfit_final &lt;-\n  best_wf_finalized %&gt;% \n  last_fit(train_test_split)\n\ncollect_metrics(fit_final)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     141.    Preprocessor1_Model1\n2 rsq     standard       0.954 Preprocessor1_Model1\n\n\n\nfit_final %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip() \n\n\n\n\n\n\n\n\nrecfinal &lt;- \n  recipe(count ~., data = bikeshare_train) %&gt;%\n  step_mutate(date = lubridate::dmy(date)) %&gt;%\n  step_date(date,  features = c(\"dow\", \"doy\", \"week\"), keep_original_cols = FALSE) %&gt;%\n  step_mutate(date_dow = as.numeric(date_dow),\n              date_week = as.numeric(date_week)) %&gt;%\n  step_dummy(all_nominal_predictors())%&gt;% \n  step_interact(terms = ~starts_with(\"holiday\"):hour, role = \"predictor\") %&gt;% \n  step_interact(terms = ~starts_with(\"holiday\"):humidity, role = \"predictor\") %&gt;%\n  step_interact(terms = ~starts_with(\"holiday\"):rain, role = \"predictor\") %&gt;%\n  step_interact(terms = ~starts_with(\"holiday\"):date_dow, role = \"predictor\") %&gt;% \n  step_interact(terms = ~starts_with(\"func\"):temp, role = \"predictor\")\n\n\ncv_scheme2 &lt;- vfold_cv(bikeshare_train,\n  v = 5, \n  repeats = 3)\n\n\npreproc2 &lt;- list(rec81 = recfinal)\n\nmodels2 &lt;- list(cubist = mod_cubist, xgboost = mod_xg)\n\nall_workflows2 &lt;- workflow_set(preproc2, models2)\n\nmodel_set2 &lt;-\nall_workflows2 %&gt;% \nworkflow_map(\n  resamples = cv_scheme2,\n  grid = 10,\n  seed = 42,\n  verbose = TRUE)\n\ni 1 of 2 tuning:     rec81_cubist\n\n\n✔ 1 of 2 tuning:     rec81_cubist (21m 49.8s)\n\n\ni 2 of 2 tuning:     rec81_xgboost\n\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n✔ 2 of 2 tuning:     rec81_xgboost (11m 21.1s)\n\n\n\ntune::autoplot(model_set2) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nmodel_set2 %&gt;% \n  collect_metrics() %&gt;% \n  arrange(-mean)\n\n# A tibble: 40 × 9\n   wflow_id      .config    preproc model .metric .estimator  mean     n std_err\n   &lt;chr&gt;         &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n 1 rec81_xgboost Preproces… recipe  boos… rmse    standard    274.    15    2.03\n 2 rec81_xgboost Preproces… recipe  boos… rmse    standard    272.    15    2.24\n 3 rec81_xgboost Preproces… recipe  boos… rmse    standard    260.    15    1.87\n 4 rec81_xgboost Preproces… recipe  boos… rmse    standard    242.    15    1.89\n 5 rec81_cubist  Preproces… recipe  cubi… rmse    standard    183.    15    2.65\n 6 rec81_cubist  Preproces… recipe  cubi… rmse    standard    169.    15    2.57\n 7 rec81_xgboost Preproces… recipe  boos… rmse    standard    160.    15    2.33\n 8 rec81_xgboost Preproces… recipe  boos… rmse    standard    159.    15    2.10\n 9 rec81_xgboost Preproces… recipe  boos… rmse    standard    159.    15    2.24\n10 rec81_xgboost Preproces… recipe  boos… rmse    standard    151.    15    2.48\n# ℹ 30 more rows\n\n\n\nbest_model_params2 &lt;- \n  extract_workflow_set_result(model_set2, \"rec81_cubist\") %&gt;% \n  select_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\nbest_wf2 &lt;- \nall_workflows2 %&gt;% \n  extract_workflow(\"rec81_cubist\")\n\nbest_wf_finalized2 &lt;- \n  best_wf2 %&gt;% \n  finalize_workflow(best_model_params2)\n\nfit_final2 &lt;-\n  best_wf_finalized2 %&gt;% \n  fit(bikeshare_train)\n\n\n\n\nBei der Vorhersage ist zu beachten, dass es im Train-Sample keine Ausleihungen an funktionalen Tagen gab. Es ist eine vernünftige Annahme, dass dies im Test-Sample wahrscheinlich genauso sein wird. Daher werden manuell alle Vorhersagen für nicht funktionale Tage auf null gesetzt.\n\nfinal_preds &lt;- \n  fit_final2 %&gt;% \n  predict(new_data = bikeshare_test) %&gt;% \n  bind_cols(bikeshare_test)\n\nsubmission_df &lt;-\n  final_preds %&gt;%\n  mutate(id = row_number()) %&gt;%\n  mutate(pred = case_when(func == \"No\" ~ 0,\n                            TRUE ~ .pred)) %&gt;% \n  select(id, pred)\n\n\nsubmission_df %&gt;% \n  ggplot() +\n  aes(pred) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nwrite.csv(submission_df, file = \"Balzer_Raphael_00163021_Prognose.csv\", row.names = FALSE)"
  },
  {
    "objectID": "posts/Bikeshare Analyse/bikeshare.html#vorbereitung",
    "href": "posts/Bikeshare Analyse/bikeshare.html#vorbereitung",
    "title": "bikeshare prediction",
    "section": "",
    "text": "library(ggcorrplot)\n\nLoading required package: ggplot2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\nlibrary(easystats)\n\n# Attaching packages: easystats 0.6.0 (red = needs update)\n✔ bayestestR  0.13.1   ✔ correlation 0.8.4 \n✖ datawizard  0.7.1    ✖ effectsize  0.8.3 \n✖ insight     0.19.2   ✔ modelbased  0.8.6 \n✖ performance 0.10.3   ✖ parameters  0.21.1\n✔ report      0.5.7    ✖ see         0.7.5 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.2.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tibble       3.2.1\n✔ dplyr        1.1.2     ✔ tidyr        1.3.0\n✔ infer        1.0.4     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.1     ✔ yardstick    1.2.0\n✔ recipes      1.0.8     \n\n\nWarning: package 'broom' was built under R version 4.2.3\n\n\nWarning: package 'dials' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'modeldata' was built under R version 4.2.3\n\n\nWarning: package 'parsnip' was built under R version 4.2.3\n\n\nWarning: package 'recipes' was built under R version 4.2.3\n\n\nWarning: package 'rsample' was built under R version 4.2.3\n\n\nWarning: package 'tibble' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\nWarning: package 'tune' was built under R version 4.2.3\n\n\nWarning: package 'workflowsets' was built under R version 4.2.3\n\n\nWarning: package 'yardstick' was built under R version 4.2.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()         masks scales::discard()\n✖ dplyr::filter()          masks stats::filter()\n✖ yardstick::get_weights() masks insight::get_weights()\n✖ dplyr::lag()             masks stats::lag()\n✖ yardstick::mae()         masks performance::mae()\n✖ parsnip::null_model()    masks insight::null_model()\n✖ infer::p_value()         masks parameters::p_value()\n✖ tune::parameters()       masks dials::parameters(), parameters::parameters()\n✖ yardstick::rmse()        masks performance::rmse()\n✖ dials::smoothness()      masks datawizard::smoothness()\n✖ recipes::step()          masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ readr   2.1.3     ✔ forcats 1.0.0\n✔ stringr 1.5.0     \n\n\nWarning: package 'forcats' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\n\nlibrary(corrr)\nlibrary(tidytext)\n\nWarning: package 'tidytext' was built under R version 4.2.3\n\nlibrary(ggthemes)\nlibrary(ggplot2)\nlibrary(GGally)\n\nWarning: package 'GGally' was built under R version 4.2.3\n\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nlibrary(lubridate)\n\nWarning: package 'lubridate' was built under R version 4.2.3\n\n\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(xgboost)\n\nWarning: package 'xgboost' was built under R version 4.2.3\n\n\n\nAttaching package: 'xgboost'\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\nlibrary(Cubist)\n\nWarning: package 'Cubist' was built under R version 4.2.3\n\n\nLoading required package: lattice\n\nlibrary(rules)\n\nWarning: package 'rules' was built under R version 4.2.3\n\n\n\nAttaching package: 'rules'\n\nThe following object is masked from 'package:dials':\n\n    max_rules\n\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.2.3\n\n\n\nAttaching package: 'caret'\n\nThe following objects are masked from 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nThe following object is masked from 'package:parameters':\n\n    compare_models\n\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.2.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\n\n\n\n\n\nlibrary(readr)\nbikeshare_test &lt;- read_csv(\"bikeshare_test.csv\")\n\nRows: 2192 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): date, season, holiday, func\ndbl (9): hour, temp, humidity, windspeed, visibility, dewpointtemp, solar, r...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nlibrary(readr)\nbikeshare_train &lt;- read_csv(\"bikeshare_train.csv\")\n\nRows: 6568 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): date, season, holiday, func\ndbl (10): count, hour, temp, humidity, windspeed, visibility, dewpointtemp, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbikeshare_train\n\n# A tibble: 6,568 × 14\n   date       count  hour  temp humidity windspeed visibility dewpointtemp solar\n   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 01/12/2017   173     2  -6         39       1         2000        -17.7     0\n 2 01/12/2017   107     3  -6.2       40       0.9       2000        -17.6     0\n 3 01/12/2017    78     4  -6         36       2.3       2000        -18.6     0\n 4 01/12/2017   100     5  -6.4       37       1.5       2000        -18.7     0\n 5 01/12/2017   181     6  -6.6       35       1.3       2000        -19.5     0\n 6 02/12/2017   167     3  -3.5       81       2.2       1221         -6.2     0\n 7 02/12/2017    89     4  -3.8       79       2         1167         -6.9     0\n 8 02/12/2017    70     6  -4.3       82       2.1       1178         -6.9     0\n 9 02/12/2017   146     7  -4.4       81       2.5       1276         -7.1     0\n10 03/12/2017    32     5   3.9       75       1.9        914         -0.1     0\n# ℹ 6,558 more rows\n# ℹ 5 more variables: rain &lt;dbl&gt;, snow &lt;dbl&gt;, season &lt;chr&gt;, holiday &lt;chr&gt;,\n#   func &lt;chr&gt;"
  },
  {
    "objectID": "posts/Bikeshare Analyse/bikeshare.html#explorative-datenanalyse",
    "href": "posts/Bikeshare Analyse/bikeshare.html#explorative-datenanalyse",
    "title": "bikeshare prediction",
    "section": "",
    "text": "bikeshare_train %&gt;% \n  ggcorr(label = TRUE)\n\nWarning in ggcorr(., label = TRUE): data in column(s) 'date', 'season',\n'holiday', 'func' are not numeric and were ignored\n\n\n\n\n\n\n\n\n\nbikeshare_train %&gt;% \n  summarise((across(everything(),~sum(is.na(.x)))))\n\n# A tibble: 1 × 14\n   date count  hour  temp humidity windspeed visibility dewpointtemp solar  rain\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;     &lt;int&gt;      &lt;int&gt;        &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     0     0     0     0        0         0          0            0     0     0\n# ℹ 4 more variables: snow &lt;int&gt;, season &lt;int&gt;, holiday &lt;int&gt;, func &lt;int&gt;\n\n\n\nbikeshare_test %&gt;%\n  summarise((across(everything(),~sum(is.na(.x)))))\n\n# A tibble: 1 × 13\n   date  hour  temp humidity windspeed visibility dewpointtemp solar  rain  snow\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;     &lt;int&gt;      &lt;int&gt;        &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     0     0     0        0         0          0            0     0     0     0\n# ℹ 3 more variables: season &lt;int&gt;, holiday &lt;int&gt;, func &lt;int&gt;\n\n\n\nvisdat::vis_dat(bikeshare_train)\n\n\n\n\n\n\n\n\nbikeshare_train %&gt;% \n  select(where(is.numeric)) %&gt;% \n  pivot_longer(everything()) %&gt;% \nggplot(., aes(x = value)) +\n  geom_boxplot(fill = \"#4E79A7\") +\n  theme_minimal() +\n  facet_wrap(~ name, scales = \"free_x\")\n\n\n\n\n\nbikeshare_test %&gt;% \n  select(where(is.numeric)) %&gt;% \n  pivot_longer(everything()) %&gt;% \nggplot(., aes(x = value)) +\n  geom_boxplot(fill = \"#4E79A7\") +\n  theme_minimal() +\n  facet_wrap(~ name, scales = \"free_x\")\n\n\n\n\n\n\n\n\nbikeshare_train %&gt;% \n  select(where(is.numeric)) %&gt;% \n  pivot_longer(everything()) %&gt;% \nggplot(., aes(x = value)) +\n  geom_histogram(fill = \"#4E79A7\") +\n  theme_minimal() +\n  facet_wrap(~ name, scales = \"free_x\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nbikeshare_test %&gt;% \n  select(where(is.numeric)) %&gt;% \n  pivot_longer(everything()) %&gt;%  \nggplot(., aes(x = value)) +\n  geom_histogram(fill = \"#4E79A7\") +\n  theme_minimal() +\n  facet_wrap(~ name, scales = \"free_x\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nbikeshare_train %&gt;%\n  pivot_longer(cols = 2:11) %&gt;%  \n  ggplot(., aes(x = value, fill = season)) +\n  geom_boxplot() +\n  facet_wrap(~ name, scales = \"free_x\") +\n  scale_fill_tableau() +\n  theme_minimal()\n\n\n\n\n\nbikeshare_train %&gt;%\n  pivot_longer(cols = 2:11) %&gt;%  \n  ggplot(., aes(x = value, fill = holiday)) +\n  geom_boxplot() +\n  facet_wrap(~ name, scales = \"free_x\") +\n  scale_fill_tableau() +\n  theme_minimal()\n\n\n\n\n\nbikeshare_train %&gt;%\n  pivot_longer(cols = 2:11) %&gt;%  \n  ggplot(., aes(x = value, fill = func)) +\n  geom_boxplot() +\n  facet_wrap(~ name, scales = \"free_x\") +\n  scale_fill_tableau() +\n  theme_minimal()\n\n\n\n\n\nbikeshare_train %&gt;% \n  ggplot(aes(x = season, fill = holiday)) +\n  geom_bar(alpha = 0.8) +\n  coord_flip() +\n  scale_fill_tableau() +\n  theme_minimal()\n\n\n\n\n\nbikeshare_train %&gt;% \n  ggplot(aes(x = season, fill = func)) +\n  geom_bar(alpha = 0.8) +\n  coord_flip() +\n  scale_fill_tableau() +\n  theme_minimal()\n\n\n\n\n\nbikeshare_train %&gt;% \n  mutate(hour = factor(hour)) %&gt;% \n  ggplot()+\n  aes(hour, count, fill = hour) +\n  geom_boxplot(show.legend = FALSE, alpha = 0.8) +\n  scale_fill_viridis_d() +\n  theme_minimal()\n\n\n\n\n\nbikeshare_train %&gt;%  \n  ggplot()+\n  aes(hour, count) +\n  geom_smooth(color = \"#4E79A7\", linewidth = 2 ) +\n  theme_minimal()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\nbikeshare_train %&gt;%  \n  ggplot()+\n  aes(hour, temp) +\n  geom_smooth(color = \"#4E79A7\", linewidth = 2 ) +\n  theme_minimal()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\nbikeshare_train %&gt;%  \n  ggplot()+\n  aes(hour, humidity) +\n  geom_smooth(color = \"#4E79A7\", linewidth = 2 ) +\n  theme_minimal()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\nbikeshare_train %&gt;%  \n  ggplot()+\n  aes(hour, windspeed) +\n  geom_smooth(color = \"#4E79A7\", linewidth = 2 ) +\n  theme_minimal()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\nbikeshare_train %&gt;%  \n  ggplot()+\n  aes(hour, visibility) +\n  geom_smooth(color = \"#4E79A7\", linewidth = 2 ) +\n  theme_minimal()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\nEs gibt keine fehlenden Werte, Extremwerte sind auch äußerst rar. Durch die explorativen Datenanalyse ist deutlich zu erkennen, dass die Ausleihungen nach Jahres- und Uhrzeit stark variieren. Außerdem sind die Ausleihungen an Arbeitstagen höher. Bei nicht funktionalen Tagen finden keine Ausleihungen statt. Diese Beobachtung gilt es für die Vorhersagen im Hinterkopf zu behalten. Außerdem haben die Wettervariablen ihre Hoch- oder Tiefpunkte zu ungefähr derselben Uhrzeit, zu der auch am meisten Fahrräder geliehen werden."
  },
  {
    "objectID": "posts/Bikeshare Analyse/bikeshare.html#modellierung",
    "href": "posts/Bikeshare Analyse/bikeshare.html#modellierung",
    "title": "bikeshare prediction",
    "section": "",
    "text": "set.seed(42)\n\ntrain_test_split &lt;- initial_split(bikeshare_train, prop = 0.7497717)\nbikeshare_train1 &lt;- training(train_test_split)\nbikeshare_test1 &lt;- testing(train_test_split)\n\n\n\n\nDas Hauptaugenmerk bei den Rezepten liegt auf der Datumsspalte und den Interaktionen. Nach der Umwandlung in ein Datumsformat können mit step_date() einige interessante Features extrahiert werden. Außerdem gibt es einige interessante Interaktionseffekte. Die folgenden zwei Rezepte liefern die besten Vorhersagen und unterscheiden sich nur hinsichtlich der Normalisierung der Prädiktoren:\n\nrec72 &lt;- \n  recipe(count ~., data = bikeshare_train1) %&gt;%\n  step_mutate(date = lubridate::dmy(date)) %&gt;%\n  step_date(date,  features = c(\"dow\", \"doy\", \"week\"), keep_original_cols = FALSE) %&gt;%\n  step_mutate(date_dow = as.numeric(date_dow),\n              date_week = as.numeric(date_week)) %&gt;%\n  step_normalize(all_numeric_predictors(), -c(hour, date_doy, date_dow, date_week)) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_interact(terms = ~starts_with(\"holiday\"):hour, role = \"predictor\") %&gt;% \n  step_interact(terms = ~starts_with(\"holiday\"):humidity, role = \"predictor\") %&gt;%\n  step_interact(terms = ~starts_with(\"holiday\"):rain, role = \"predictor\") %&gt;%\n  step_interact(terms = ~starts_with(\"holiday\"):date_dow, role = \"predictor\") %&gt;% \n  step_interact(terms = ~starts_with(\"func\"):temp, role = \"predictor\") \n\n\nrec81 &lt;- \n  recipe(count ~., data = bikeshare_train1) %&gt;%\n  step_mutate(date = lubridate::dmy(date)) %&gt;%\n  step_date(date,  features = c(\"dow\", \"doy\", \"week\"), keep_original_cols = FALSE) %&gt;%\n  step_mutate(date_dow = as.numeric(date_dow),\n              date_week = as.numeric(date_week)) %&gt;%\n  step_dummy(all_nominal_predictors())%&gt;% \n  step_interact(terms = ~starts_with(\"holiday\"):hour, role = \"predictor\") %&gt;% \n  step_interact(terms = ~starts_with(\"holiday\"):humidity, role = \"predictor\") %&gt;%\n  step_interact(terms = ~starts_with(\"holiday\"):rain, role = \"predictor\") %&gt;%\n  step_interact(terms = ~starts_with(\"holiday\"):date_dow, role = \"predictor\") %&gt;% \n  step_interact(terms = ~starts_with(\"func\"):temp, role = \"predictor\")"
  },
  {
    "objectID": "posts/Bikeshare Analyse/bikeshare.html#modelle",
    "href": "posts/Bikeshare Analyse/bikeshare.html#modelle",
    "title": "bikeshare prediction",
    "section": "",
    "text": "Es werden zwei starke Modelle berechnet, ein XGboost und ein Cubist. Die Wahl der Modellarten basiert hauptsächlich auf persönlichen Präferenzen. Es wird außerdem fünffache Kreuzvalidierung mit drei Wiederholungen verwendet.\n\ncv_scheme &lt;- vfold_cv(bikeshare_train1,\n  v = 5, \n  repeats = 3)\n\n\ndoParallel::registerDoParallel()\n\n\nmod_tree &lt;-\n  decision_tree(cost_complexity = tune(),\n                tree_depth = tune(),\n                min_n = tune(),\n                mode = \"regression\")\n\n\nmod_xg &lt;- boost_tree(\n  mtry = tune(), \n  trees = tune(), \n  tree_depth = tune(), \n  learn_rate = tune(), \n  min_n = tune(), \n  loss_reduction = tune()) %&gt;%\n  set_engine(\"xgboost\", nthreads = 4) %&gt;%\n  set_mode(\"regression\")\n\n\nmod_cubist &lt;- cubist_rules(\n  committees = tune(),\n  neighbors = tune(),\n  max_rules = tune()) %&gt;%\n  set_engine(\"Cubist\", nthreads = 4) %&gt;%\n  set_mode(\"regression\")\n\n\npreproc &lt;- list(rec81 = rec81, rec72 = rec72)\n\nmodels &lt;- list(cubist = mod_cubist, xgboost = mod_xg)\n\nall_workflows &lt;- workflow_set(preproc, models)\n\nmodel_set &lt;-\nall_workflows %&gt;% \nworkflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n  seed = 42,\n  verbose = TRUE)\n\ni 1 of 4 tuning:     rec81_cubist\n\n\n✔ 1 of 4 tuning:     rec81_cubist (14m 36.8s)\n\n\ni 2 of 4 tuning:     rec81_xgboost\n\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n✔ 2 of 4 tuning:     rec81_xgboost (29m 41s)\n\n\ni 3 of 4 tuning:     rec72_cubist\n\n\n✔ 3 of 4 tuning:     rec72_cubist (19m 50.1s)\n\n\ni 4 of 4 tuning:     rec72_xgboost\n\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n✔ 4 of 4 tuning:     rec72_xgboost (10m 41.3s)"
  },
  {
    "objectID": "posts/Bikeshare Analyse/bikeshare.html#ergebnisse",
    "href": "posts/Bikeshare Analyse/bikeshare.html#ergebnisse",
    "title": "bikeshare prediction",
    "section": "",
    "text": "tune::autoplot(model_set) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nmodel_set %&gt;% \n  collect_metrics() %&gt;% \n  arrange(-mean)\n\n# A tibble: 80 × 9\n   wflow_id      .config    preproc model .metric .estimator  mean     n std_err\n   &lt;chr&gt;         &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n 1 rec81_xgboost Preproces… recipe  boos… rmse    standard    273.    15    2.42\n 2 rec81_xgboost Preproces… recipe  boos… rmse    standard    270.    15    2.74\n 3 rec81_xgboost Preproces… recipe  boos… rmse    standard    267.    15    3.25\n 4 rec72_xgboost Preproces… recipe  boos… rmse    standard    267.    15    2.56\n 5 rec72_xgboost Preproces… recipe  boos… rmse    standard    266.    15    2.68\n 6 rec81_xgboost Preproces… recipe  boos… rmse    standard    249.    15    3.37\n 7 rec72_xgboost Preproces… recipe  boos… rmse    standard    244.    15    2.87\n 8 rec72_xgboost Preproces… recipe  boos… rmse    standard    243.    15    3.22\n 9 rec72_cubist  Preproces… recipe  cubi… rmse    standard    200.    15    3.25\n10 rec81_cubist  Preproces… recipe  cubi… rmse    standard    188.    15    3.16\n# ℹ 70 more rows\n\n\n\nbest_model_params &lt;- \n  extract_workflow_set_result(model_set, \"rec81_cubist\") %&gt;% \n  select_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\nbest_wf &lt;- \nall_workflows %&gt;% \n  extract_workflow(\"rec81_cubist\")\n\nbest_wf_finalized &lt;- \n  best_wf %&gt;% \n  finalize_workflow(best_model_params)\n\nfit_final &lt;-\n  best_wf_finalized %&gt;% \n  last_fit(train_test_split)\n\ncollect_metrics(fit_final)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard     141.    Preprocessor1_Model1\n2 rsq     standard       0.954 Preprocessor1_Model1\n\n\n\nfit_final %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()"
  },
  {
    "objectID": "posts/Bikeshare Analyse/bikeshare.html#trainieren-und-fitten-des-modells-auf-den-ursprünglichen-trainingsdaten",
    "href": "posts/Bikeshare Analyse/bikeshare.html#trainieren-und-fitten-des-modells-auf-den-ursprünglichen-trainingsdaten",
    "title": "bikeshare prediction",
    "section": "",
    "text": "recfinal &lt;- \n  recipe(count ~., data = bikeshare_train) %&gt;%\n  step_mutate(date = lubridate::dmy(date)) %&gt;%\n  step_date(date,  features = c(\"dow\", \"doy\", \"week\"), keep_original_cols = FALSE) %&gt;%\n  step_mutate(date_dow = as.numeric(date_dow),\n              date_week = as.numeric(date_week)) %&gt;%\n  step_dummy(all_nominal_predictors())%&gt;% \n  step_interact(terms = ~starts_with(\"holiday\"):hour, role = \"predictor\") %&gt;% \n  step_interact(terms = ~starts_with(\"holiday\"):humidity, role = \"predictor\") %&gt;%\n  step_interact(terms = ~starts_with(\"holiday\"):rain, role = \"predictor\") %&gt;%\n  step_interact(terms = ~starts_with(\"holiday\"):date_dow, role = \"predictor\") %&gt;% \n  step_interact(terms = ~starts_with(\"func\"):temp, role = \"predictor\")\n\n\ncv_scheme2 &lt;- vfold_cv(bikeshare_train,\n  v = 5, \n  repeats = 3)\n\n\npreproc2 &lt;- list(rec81 = recfinal)\n\nmodels2 &lt;- list(cubist = mod_cubist, xgboost = mod_xg)\n\nall_workflows2 &lt;- workflow_set(preproc2, models2)\n\nmodel_set2 &lt;-\nall_workflows2 %&gt;% \nworkflow_map(\n  resamples = cv_scheme2,\n  grid = 10,\n  seed = 42,\n  verbose = TRUE)\n\ni 1 of 2 tuning:     rec81_cubist\n\n\n✔ 1 of 2 tuning:     rec81_cubist (21m 49.8s)\n\n\ni 2 of 2 tuning:     rec81_xgboost\n\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n✔ 2 of 2 tuning:     rec81_xgboost (11m 21.1s)\n\n\n\ntune::autoplot(model_set2) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nmodel_set2 %&gt;% \n  collect_metrics() %&gt;% \n  arrange(-mean)\n\n# A tibble: 40 × 9\n   wflow_id      .config    preproc model .metric .estimator  mean     n std_err\n   &lt;chr&gt;         &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n 1 rec81_xgboost Preproces… recipe  boos… rmse    standard    274.    15    2.03\n 2 rec81_xgboost Preproces… recipe  boos… rmse    standard    272.    15    2.24\n 3 rec81_xgboost Preproces… recipe  boos… rmse    standard    260.    15    1.87\n 4 rec81_xgboost Preproces… recipe  boos… rmse    standard    242.    15    1.89\n 5 rec81_cubist  Preproces… recipe  cubi… rmse    standard    183.    15    2.65\n 6 rec81_cubist  Preproces… recipe  cubi… rmse    standard    169.    15    2.57\n 7 rec81_xgboost Preproces… recipe  boos… rmse    standard    160.    15    2.33\n 8 rec81_xgboost Preproces… recipe  boos… rmse    standard    159.    15    2.10\n 9 rec81_xgboost Preproces… recipe  boos… rmse    standard    159.    15    2.24\n10 rec81_xgboost Preproces… recipe  boos… rmse    standard    151.    15    2.48\n# ℹ 30 more rows\n\n\n\nbest_model_params2 &lt;- \n  extract_workflow_set_result(model_set2, \"rec81_cubist\") %&gt;% \n  select_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\nbest_wf2 &lt;- \nall_workflows2 %&gt;% \n  extract_workflow(\"rec81_cubist\")\n\nbest_wf_finalized2 &lt;- \n  best_wf2 %&gt;% \n  finalize_workflow(best_model_params2)\n\nfit_final2 &lt;-\n  best_wf_finalized2 %&gt;% \n  fit(bikeshare_train)"
  },
  {
    "objectID": "posts/Bikeshare Analyse/bikeshare.html#vorhersage-auf-das-test-sample",
    "href": "posts/Bikeshare Analyse/bikeshare.html#vorhersage-auf-das-test-sample",
    "title": "bikeshare prediction",
    "section": "",
    "text": "Bei der Vorhersage ist zu beachten, dass es im Train-Sample keine Ausleihungen an funktionalen Tagen gab. Es ist eine vernünftige Annahme, dass dies im Test-Sample wahrscheinlich genauso sein wird. Daher werden manuell alle Vorhersagen für nicht funktionale Tage auf null gesetzt.\n\nfinal_preds &lt;- \n  fit_final2 %&gt;% \n  predict(new_data = bikeshare_test) %&gt;% \n  bind_cols(bikeshare_test)\n\nsubmission_df &lt;-\n  final_preds %&gt;%\n  mutate(id = row_number()) %&gt;%\n  mutate(pred = case_when(func == \"No\" ~ 0,\n                            TRUE ~ .pred)) %&gt;% \n  select(id, pred)\n\n\nsubmission_df %&gt;% \n  ggplot() +\n  aes(pred) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nwrite.csv(submission_df, file = \"Balzer_Raphael_00163021_Prognose.csv\", row.names = FALSE)"
  },
  {
    "objectID": "posts/bikeshare_python/bike_python.html",
    "href": "posts/bikeshare_python/bike_python.html",
    "title": "bikeshare python",
    "section": "",
    "text": "Bikeshare-Vorhersage aber diesmal in Python.\n\n\n\n\n\nimport pandas as pd\n\n\ndf=pd.read_csv('https://archive.ics.uci.edu/static/public/560/seoul+bike+sharing+demand.zip',encoding= 'unicode_escape',parse_dates=[\"Date\"],dayfirst= \"true\")\n\n\ndf.head(5)\n\n\n\n\n\n\n\n\nDate\nRented Bike Count\nHour\nTemperature(°C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(°C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nSeasons\nHoliday\nFunctioning Day\n\n\n\n\n0\n2017-12-01\n254\n0\n-5.2\n37\n2.2\n2000\n-17.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n1\n2017-12-01\n204\n1\n-5.5\n38\n0.8\n2000\n-17.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n2\n2017-12-01\n173\n2\n-6.0\n39\n1.0\n2000\n-17.7\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n3\n2017-12-01\n107\n3\n-6.2\n40\n0.9\n2000\n-17.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n4\n2017-12-01\n78\n4\n-6.0\n36\n2.3\n2000\n-18.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 8760 entries, 0 to 8759\nData columns (total 14 columns):\n #   Column                     Non-Null Count  Dtype         \n---  ------                     --------------  -----         \n 0   Date                       8760 non-null   datetime64[ns]\n 1   Rented Bike Count          8760 non-null   int64         \n 2   Hour                       8760 non-null   int64         \n 3   Temperature(°C)            8760 non-null   float64       \n 4   Humidity(%)                8760 non-null   int64         \n 5   Wind speed (m/s)           8760 non-null   float64       \n 6   Visibility (10m)           8760 non-null   int64         \n 7   Dew point temperature(°C)  8760 non-null   float64       \n 8   Solar Radiation (MJ/m2)    8760 non-null   float64       \n 9   Rainfall(mm)               8760 non-null   float64       \n 10  Snowfall (cm)              8760 non-null   float64       \n 11  Seasons                    8760 non-null   object        \n 12  Holiday                    8760 non-null   object        \n 13  Functioning Day            8760 non-null   object        \ndtypes: datetime64[ns](1), float64(6), int64(4), object(3)\nmemory usage: 958.3+ KB\n\n\n\n\n\n\ndf.nunique().sort_values()\n\nHoliday                         2\nFunctioning Day                 2\nSeasons                         4\nHour                           24\nSnowfall (cm)                  51\nRainfall(mm)                   61\nWind speed (m/s)               65\nHumidity(%)                    90\nSolar Radiation (MJ/m2)       345\nDate                          365\nTemperature(°C)               546\nDew point temperature(°C)     556\nVisibility (10m)             1789\nRented Bike Count            2166\ndtype: int64\n\n\n\n\n\n\ndf.isnull().sum()\n\nDate                         0\nRented Bike Count            0\nHour                         0\nTemperature(°C)              0\nHumidity(%)                  0\nWind speed (m/s)             0\nVisibility (10m)             0\nDew point temperature(°C)    0\nSolar Radiation (MJ/m2)      0\nRainfall(mm)                 0\nSnowfall (cm)                0\nSeasons                      0\nHoliday                      0\nFunctioning Day              0\ndtype: int64\n\n\n\n\n\n\n\n\n\ndf=pd.get_dummies(df,columns=['Holiday','Seasons','Functioning Day'],drop_first=True)\n\n\n\n\n\ndf['Date'] = pd.to_datetime(df['Date'])\n\ndf['Day']=df['Date'].dt.day\ndf['Month']=df['Date'].dt.month\ndf['Year']=df['Date'].dt.year\ndf.drop(columns=['Date'],inplace=True)\ndf.head()\n\n\n\n\n\n\n\n\nRented Bike Count\nHour\nTemperature(°C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(°C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nHoliday_No Holiday\nSeasons_Spring\nSeasons_Summer\nSeasons_Winter\nFunctioning Day_Yes\nDay\nMonth\nYear\n\n\n\n\n0\n254\n0\n-5.2\n37\n2.2\n2000\n-17.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n1\n204\n1\n-5.5\n38\n0.8\n2000\n-17.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n2\n173\n2\n-6.0\n39\n1.0\n2000\n-17.7\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n3\n107\n3\n-6.2\n40\n0.9\n2000\n-17.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n4\n78\n4\n-6.0\n36\n2.3\n2000\n-18.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ny = df[\"Rented Bike Count\"]\ny\n\n0        254\n1        204\n2        173\n3        107\n4         78\n        ... \n8755    1003\n8756     764\n8757     694\n8758     712\n8759     584\nName: Rented Bike Count, Length: 8760, dtype: int64\n\n\n\nX = df.drop([\"Rented Bike Count\"], axis = 1)\nX\n\n\n\n\n\n\n\n\nHour\nTemperature(°C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(°C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nHoliday_No Holiday\nSeasons_Spring\nSeasons_Summer\nSeasons_Winter\nFunctioning Day_Yes\nDay\nMonth\nYear\n\n\n\n\n0\n0\n-5.2\n37\n2.2\n2000\n-17.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n1\n1\n-5.5\n38\n0.8\n2000\n-17.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n2\n2\n-6.0\n39\n1.0\n2000\n-17.7\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n3\n3\n-6.2\n40\n0.9\n2000\n-17.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n4\n4\n-6.0\n36\n2.3\n2000\n-18.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n8755\n19\n4.2\n34\n2.6\n1894\n-10.3\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n30\n11\n2018\n\n\n8756\n20\n3.4\n37\n2.3\n2000\n-9.9\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n30\n11\n2018\n\n\n8757\n21\n2.6\n39\n0.3\n1968\n-9.9\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n30\n11\n2018\n\n\n8758\n22\n2.1\n41\n1.0\n1859\n-9.8\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n30\n11\n2018\n\n\n8759\n23\n1.9\n43\n1.3\n1909\n-9.3\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n30\n11\n2018\n\n\n\n\n8760 rows × 17 columns\n\n\n\n\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nX_train\n\n\n\n\n\n\n\n\nHour\nTemperature(°C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(°C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nHoliday_No Holiday\nSeasons_Spring\nSeasons_Summer\nSeasons_Winter\nFunctioning Day_Yes\nDay\nMonth\nYear\n\n\n\n\n8415\n15\n13.2\n61\n3.9\n719\n5.8\n1.03\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n16\n11\n2018\n\n\n5049\n9\n22.9\n86\n1.7\n538\n20.4\n0.76\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n29\n6\n2018\n\n\n8395\n19\n11.2\n46\n1.4\n869\n0.0\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n15\n11\n2018\n\n\n1535\n23\n-2.6\n69\n2.0\n1434\n-7.5\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n2\n2\n2018\n\n\n5518\n22\n27.2\n73\n1.5\n1005\n21.9\n0.00\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n18\n7\n2018\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5734\n22\n29.9\n74\n2.0\n1201\n24.7\n0.00\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n27\n7\n2018\n\n\n5191\n7\n23.5\n90\n0.5\n445\n21.7\n0.05\n0.5\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n5\n7\n2018\n\n\n5390\n14\n29.5\n62\n2.7\n1941\n21.4\n1.79\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n13\n7\n2018\n\n\n860\n20\n-3.4\n51\n1.1\n1391\n-12.1\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n5\n1\n2018\n\n\n7270\n22\n19.3\n55\n0.5\n2000\n10.0\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n29\n9\n2018\n\n\n\n\n7008 rows × 17 columns\n\n\n\n\nX_test\n\n\n\n\n\n\n\n\nHour\nTemperature(°C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(°C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nHoliday_No Holiday\nSeasons_Spring\nSeasons_Summer\nSeasons_Winter\nFunctioning Day_Yes\nDay\nMonth\nYear\n\n\n\n\n6056\n8\n27.2\n69\n1.8\n1999\n21.0\n0.70\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n10\n8\n2018\n\n\n5556\n12\n32.6\n51\n2.1\n800\n21.1\n3.21\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n20\n7\n2018\n\n\n5990\n14\n34.0\n50\n1.2\n1744\n22.1\n1.68\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n7\n8\n2018\n\n\n7674\n18\n16.9\n47\n1.4\n1637\n5.5\n0.11\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n16\n10\n2018\n\n\n3319\n7\n6.4\n51\n1.0\n1398\n-3.0\n0.19\n0.0\n0.0\nTrue\nTrue\nFalse\nFalse\nTrue\n18\n4\n2018\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n8307\n3\n4.6\n65\n0.1\n2000\n-1.4\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n12\n11\n2018\n\n\n100\n4\n-7.2\n34\n3.0\n2000\n-20.4\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n5\n12\n2017\n\n\n6605\n5\n20.6\n65\n1.1\n2000\n13.7\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n2\n9\n2018\n\n\n1783\n7\n-7.2\n70\n1.9\n1946\n-11.7\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n13\n2\n2018\n\n\n6013\n13\n34.4\n48\n2.1\n1921\n21.7\n2.37\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n8\n8\n2018\n\n\n\n\n1752 rows × 17 columns\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LinearRegression\n\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\n\n\n\ny_lm_train_pred = lm.predict(X_train)\ny_lm_test_pred = lm.predict(X_test)\n\n\n\n\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\n\nlm_train_rmse=np.sqrt(mean_squared_error(y_train, y_lm_train_pred))\nlm_train_rmse\n\n428.36787459866156\n\n\n\nlm_test_rmse = np.sqrt(mean_squared_error(y_test, y_lm_test_pred))\nlm_test_rmse\n\n440.49073091861925\n\n\n\nr2_score(y_train, y_lm_train_pred)\n\n0.5586908577971319\n\n\n\n\n\n\n\n\n\nfrom sklearn.model_selection import GridSearchCV\nimport xgboost as xgb\n\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'learning_rate': [0.01, 0.1, 0.2],\n    'max_depth': [3, 4, 5],\n}\n\n\nxgb_model = xgb.XGBRegressor()\n\n\ngrid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n\n\ngrid_search.fit(X_train, y_train)\n\nGridSearchCV(cv=5,\n             estimator=XGBRegressor(base_score=None, booster=None,\n                                    callbacks=None, colsample_bylevel=None,\n                                    colsample_bynode=None,\n                                    colsample_bytree=None, device=None,\n                                    early_stopping_rounds=None,\n                                    enable_categorical=False, eval_metric=None,\n                                    feature_types=None, gamma=None,\n                                    grow_policy=None, importance_type=None,\n                                    interaction_constraints=None,\n                                    learning_rate=None, m...\n                                    max_cat_to_onehot=None, max_delta_step=None,\n                                    max_depth=None, max_leaves=None,\n                                    min_child_weight=None, missing=nan,\n                                    monotone_constraints=None,\n                                    multi_strategy=None, n_estimators=None,\n                                    n_jobs=None, num_parallel_tree=None,\n                                    random_state=None, ...),\n             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n                         'max_depth': [3, 4, 5],\n                         'n_estimators': [100, 200, 300]},\n             scoring='neg_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5,\n             estimator=XGBRegressor(base_score=None, booster=None,\n                                    callbacks=None, colsample_bylevel=None,\n                                    colsample_bynode=None,\n                                    colsample_bytree=None, device=None,\n                                    early_stopping_rounds=None,\n                                    enable_categorical=False, eval_metric=None,\n                                    feature_types=None, gamma=None,\n                                    grow_policy=None, importance_type=None,\n                                    interaction_constraints=None,\n                                    learning_rate=None, m...\n                                    max_cat_to_onehot=None, max_delta_step=None,\n                                    max_depth=None, max_leaves=None,\n                                    min_child_weight=None, missing=nan,\n                                    monotone_constraints=None,\n                                    multi_strategy=None, n_estimators=None,\n                                    n_jobs=None, num_parallel_tree=None,\n                                    random_state=None, ...),\n             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n                         'max_depth': [3, 4, 5],\n                         'n_estimators': [100, 200, 300]},\n             scoring='neg_mean_squared_error')estimator: XGBRegressorXGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)XGBRegressorXGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)\n\n\n\nbest_model = grid_search.best_estimator_\nbest_model\n\nXGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=5, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=300, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.XGBRegressorXGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=5, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=300, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)\n\n\n\n\n\n\nbest_model.score(X_test, y_test)\n\n0.8850799773550728\n\n\n\ny_xgb_test_pred = best_model.predict(X_test)\n\n\nxgb_test_rmse = np.sqrt(mean_squared_error(y_test, y_xgb_test_pred))\nxgb_test_rmse\n\n218.81726410952444\n\n\n\n\n\n\nX_test['pred'] = y_xgb_test_pred\nX_test.loc[X_test['Functioning Day_Yes'] == 0, 'pred'] = 0\nX_test.loc[X_test[\"pred\"] &lt; 0, \"pred\"] = 0\nX_test\n\n\n\n\n\n\n\n\nHour\nTemperature(°C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(°C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nHoliday_No Holiday\nSeasons_Spring\nSeasons_Summer\nSeasons_Winter\nFunctioning Day_Yes\nDay\nMonth\nYear\npred\n\n\n\n\n6056\n8\n27.2\n69\n1.8\n1999\n21.0\n0.70\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n10\n8\n2018\n1524.514648\n\n\n5556\n12\n32.6\n51\n2.1\n800\n21.1\n3.21\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n20\n7\n2018\n732.632812\n\n\n5990\n14\n34.0\n50\n1.2\n1744\n22.1\n1.68\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n7\n8\n2018\n712.731140\n\n\n7674\n18\n16.9\n47\n1.4\n1637\n5.5\n0.11\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n16\n10\n2018\n2194.891357\n\n\n3319\n7\n6.4\n51\n1.0\n1398\n-3.0\n0.19\n0.0\n0.0\nTrue\nTrue\nFalse\nFalse\nTrue\n18\n4\n2018\n639.635742\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n8307\n3\n4.6\n65\n0.1\n2000\n-1.4\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n12\n11\n2018\n292.208466\n\n\n100\n4\n-7.2\n34\n3.0\n2000\n-20.4\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n5\n12\n2017\n89.085770\n\n\n6605\n5\n20.6\n65\n1.1\n2000\n13.7\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n2\n9\n2018\n266.967682\n\n\n1783\n7\n-7.2\n70\n1.9\n1946\n-11.7\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n13\n2\n2018\n220.198990\n\n\n6013\n13\n34.4\n48\n2.1\n1921\n21.7\n2.37\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n8\n8\n2018\n663.002563\n\n\n\n\n1752 rows × 18 columns\n\n\n\n\nnp.sqrt(mean_squared_error(y_test, X_test[\"pred\"]))\n\n217.4355409172396\n\n\n\npred_df = X_test[['pred']]\npred_df = pred_df.reset_index(drop=True)\npred_df.insert(0, 'id', range(1, len(pred_df) + 1))\npred_df\n\n\n\n\n\n\n\n\nid\npred\n\n\n\n\n0\n1\n1524.514648\n\n\n1\n2\n732.632812\n\n\n2\n3\n712.731140\n\n\n3\n4\n2194.891357\n\n\n4\n5\n639.635742\n\n\n...\n...\n...\n\n\n1747\n1748\n292.208466\n\n\n1748\n1749\n89.085770\n\n\n1749\n1750\n266.967682\n\n\n1750\n1751\n220.198990\n\n\n1751\n1752\n663.002563\n\n\n\n\n1752 rows × 2 columns\n\n\n\n\npred_df.to_csv('pred_values.csv', index = False)"
  },
  {
    "objectID": "posts/bikeshare_python/bike_python.html#eda",
    "href": "posts/bikeshare_python/bike_python.html#eda",
    "title": "bikeshare python",
    "section": "",
    "text": "import pandas as pd\n\n\ndf=pd.read_csv('https://archive.ics.uci.edu/static/public/560/seoul+bike+sharing+demand.zip',encoding= 'unicode_escape',parse_dates=[\"Date\"],dayfirst= \"true\")\n\n\ndf.head(5)\n\n\n\n\n\n\n\n\nDate\nRented Bike Count\nHour\nTemperature(°C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(°C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nSeasons\nHoliday\nFunctioning Day\n\n\n\n\n0\n2017-12-01\n254\n0\n-5.2\n37\n2.2\n2000\n-17.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n1\n2017-12-01\n204\n1\n-5.5\n38\n0.8\n2000\n-17.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n2\n2017-12-01\n173\n2\n-6.0\n39\n1.0\n2000\n-17.7\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n3\n2017-12-01\n107\n3\n-6.2\n40\n0.9\n2000\n-17.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n4\n2017-12-01\n78\n4\n-6.0\n36\n2.3\n2000\n-18.6\n0.0\n0.0\n0.0\nWinter\nNo Holiday\nYes\n\n\n\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 8760 entries, 0 to 8759\nData columns (total 14 columns):\n #   Column                     Non-Null Count  Dtype         \n---  ------                     --------------  -----         \n 0   Date                       8760 non-null   datetime64[ns]\n 1   Rented Bike Count          8760 non-null   int64         \n 2   Hour                       8760 non-null   int64         \n 3   Temperature(°C)            8760 non-null   float64       \n 4   Humidity(%)                8760 non-null   int64         \n 5   Wind speed (m/s)           8760 non-null   float64       \n 6   Visibility (10m)           8760 non-null   int64         \n 7   Dew point temperature(°C)  8760 non-null   float64       \n 8   Solar Radiation (MJ/m2)    8760 non-null   float64       \n 9   Rainfall(mm)               8760 non-null   float64       \n 10  Snowfall (cm)              8760 non-null   float64       \n 11  Seasons                    8760 non-null   object        \n 12  Holiday                    8760 non-null   object        \n 13  Functioning Day            8760 non-null   object        \ndtypes: datetime64[ns](1), float64(6), int64(4), object(3)\nmemory usage: 958.3+ KB\n\n\n\n\n\n\ndf.nunique().sort_values()\n\nHoliday                         2\nFunctioning Day                 2\nSeasons                         4\nHour                           24\nSnowfall (cm)                  51\nRainfall(mm)                   61\nWind speed (m/s)               65\nHumidity(%)                    90\nSolar Radiation (MJ/m2)       345\nDate                          365\nTemperature(°C)               546\nDew point temperature(°C)     556\nVisibility (10m)             1789\nRented Bike Count            2166\ndtype: int64\n\n\n\n\n\n\ndf.isnull().sum()\n\nDate                         0\nRented Bike Count            0\nHour                         0\nTemperature(°C)              0\nHumidity(%)                  0\nWind speed (m/s)             0\nVisibility (10m)             0\nDew point temperature(°C)    0\nSolar Radiation (MJ/m2)      0\nRainfall(mm)                 0\nSnowfall (cm)                0\nSeasons                      0\nHoliday                      0\nFunctioning Day              0\ndtype: int64"
  },
  {
    "objectID": "posts/bikeshare_python/bike_python.html#vorverarbeitung",
    "href": "posts/bikeshare_python/bike_python.html#vorverarbeitung",
    "title": "bikeshare python",
    "section": "",
    "text": "df=pd.get_dummies(df,columns=['Holiday','Seasons','Functioning Day'],drop_first=True)\n\n\n\n\n\ndf['Date'] = pd.to_datetime(df['Date'])\n\ndf['Day']=df['Date'].dt.day\ndf['Month']=df['Date'].dt.month\ndf['Year']=df['Date'].dt.year\ndf.drop(columns=['Date'],inplace=True)\ndf.head()\n\n\n\n\n\n\n\n\nRented Bike Count\nHour\nTemperature(°C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(°C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nHoliday_No Holiday\nSeasons_Spring\nSeasons_Summer\nSeasons_Winter\nFunctioning Day_Yes\nDay\nMonth\nYear\n\n\n\n\n0\n254\n0\n-5.2\n37\n2.2\n2000\n-17.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n1\n204\n1\n-5.5\n38\n0.8\n2000\n-17.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n2\n173\n2\n-6.0\n39\n1.0\n2000\n-17.7\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n3\n107\n3\n-6.2\n40\n0.9\n2000\n-17.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n4\n78\n4\n-6.0\n36\n2.3\n2000\n-18.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017"
  },
  {
    "objectID": "posts/bikeshare_python/bike_python.html#modellierung",
    "href": "posts/bikeshare_python/bike_python.html#modellierung",
    "title": "bikeshare python",
    "section": "",
    "text": "y = df[\"Rented Bike Count\"]\ny\n\n0        254\n1        204\n2        173\n3        107\n4         78\n        ... \n8755    1003\n8756     764\n8757     694\n8758     712\n8759     584\nName: Rented Bike Count, Length: 8760, dtype: int64\n\n\n\nX = df.drop([\"Rented Bike Count\"], axis = 1)\nX\n\n\n\n\n\n\n\n\nHour\nTemperature(°C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(°C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nHoliday_No Holiday\nSeasons_Spring\nSeasons_Summer\nSeasons_Winter\nFunctioning Day_Yes\nDay\nMonth\nYear\n\n\n\n\n0\n0\n-5.2\n37\n2.2\n2000\n-17.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n1\n1\n-5.5\n38\n0.8\n2000\n-17.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n2\n2\n-6.0\n39\n1.0\n2000\n-17.7\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n3\n3\n-6.2\n40\n0.9\n2000\n-17.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n4\n4\n-6.0\n36\n2.3\n2000\n-18.6\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n1\n12\n2017\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n8755\n19\n4.2\n34\n2.6\n1894\n-10.3\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n30\n11\n2018\n\n\n8756\n20\n3.4\n37\n2.3\n2000\n-9.9\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n30\n11\n2018\n\n\n8757\n21\n2.6\n39\n0.3\n1968\n-9.9\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n30\n11\n2018\n\n\n8758\n22\n2.1\n41\n1.0\n1859\n-9.8\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n30\n11\n2018\n\n\n8759\n23\n1.9\n43\n1.3\n1909\n-9.3\n0.0\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n30\n11\n2018\n\n\n\n\n8760 rows × 17 columns\n\n\n\n\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nX_train\n\n\n\n\n\n\n\n\nHour\nTemperature(°C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(°C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nHoliday_No Holiday\nSeasons_Spring\nSeasons_Summer\nSeasons_Winter\nFunctioning Day_Yes\nDay\nMonth\nYear\n\n\n\n\n8415\n15\n13.2\n61\n3.9\n719\n5.8\n1.03\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n16\n11\n2018\n\n\n5049\n9\n22.9\n86\n1.7\n538\n20.4\n0.76\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n29\n6\n2018\n\n\n8395\n19\n11.2\n46\n1.4\n869\n0.0\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n15\n11\n2018\n\n\n1535\n23\n-2.6\n69\n2.0\n1434\n-7.5\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n2\n2\n2018\n\n\n5518\n22\n27.2\n73\n1.5\n1005\n21.9\n0.00\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n18\n7\n2018\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5734\n22\n29.9\n74\n2.0\n1201\n24.7\n0.00\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n27\n7\n2018\n\n\n5191\n7\n23.5\n90\n0.5\n445\n21.7\n0.05\n0.5\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n5\n7\n2018\n\n\n5390\n14\n29.5\n62\n2.7\n1941\n21.4\n1.79\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n13\n7\n2018\n\n\n860\n20\n-3.4\n51\n1.1\n1391\n-12.1\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n5\n1\n2018\n\n\n7270\n22\n19.3\n55\n0.5\n2000\n10.0\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n29\n9\n2018\n\n\n\n\n7008 rows × 17 columns\n\n\n\n\nX_test\n\n\n\n\n\n\n\n\nHour\nTemperature(°C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(°C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nHoliday_No Holiday\nSeasons_Spring\nSeasons_Summer\nSeasons_Winter\nFunctioning Day_Yes\nDay\nMonth\nYear\n\n\n\n\n6056\n8\n27.2\n69\n1.8\n1999\n21.0\n0.70\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n10\n8\n2018\n\n\n5556\n12\n32.6\n51\n2.1\n800\n21.1\n3.21\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n20\n7\n2018\n\n\n5990\n14\n34.0\n50\n1.2\n1744\n22.1\n1.68\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n7\n8\n2018\n\n\n7674\n18\n16.9\n47\n1.4\n1637\n5.5\n0.11\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n16\n10\n2018\n\n\n3319\n7\n6.4\n51\n1.0\n1398\n-3.0\n0.19\n0.0\n0.0\nTrue\nTrue\nFalse\nFalse\nTrue\n18\n4\n2018\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n8307\n3\n4.6\n65\n0.1\n2000\n-1.4\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n12\n11\n2018\n\n\n100\n4\n-7.2\n34\n3.0\n2000\n-20.4\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n5\n12\n2017\n\n\n6605\n5\n20.6\n65\n1.1\n2000\n13.7\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n2\n9\n2018\n\n\n1783\n7\n-7.2\n70\n1.9\n1946\n-11.7\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n13\n2\n2018\n\n\n6013\n13\n34.4\n48\n2.1\n1921\n21.7\n2.37\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n8\n8\n2018\n\n\n\n\n1752 rows × 17 columns\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LinearRegression\n\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\n\n\n\ny_lm_train_pred = lm.predict(X_train)\ny_lm_test_pred = lm.predict(X_test)\n\n\n\n\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\n\nlm_train_rmse=np.sqrt(mean_squared_error(y_train, y_lm_train_pred))\nlm_train_rmse\n\n428.36787459866156\n\n\n\nlm_test_rmse = np.sqrt(mean_squared_error(y_test, y_lm_test_pred))\nlm_test_rmse\n\n440.49073091861925\n\n\n\nr2_score(y_train, y_lm_train_pred)\n\n0.5586908577971319\n\n\n\n\n\n\n\n\n\nfrom sklearn.model_selection import GridSearchCV\nimport xgboost as xgb\n\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'learning_rate': [0.01, 0.1, 0.2],\n    'max_depth': [3, 4, 5],\n}\n\n\nxgb_model = xgb.XGBRegressor()\n\n\ngrid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n\n\ngrid_search.fit(X_train, y_train)\n\nGridSearchCV(cv=5,\n             estimator=XGBRegressor(base_score=None, booster=None,\n                                    callbacks=None, colsample_bylevel=None,\n                                    colsample_bynode=None,\n                                    colsample_bytree=None, device=None,\n                                    early_stopping_rounds=None,\n                                    enable_categorical=False, eval_metric=None,\n                                    feature_types=None, gamma=None,\n                                    grow_policy=None, importance_type=None,\n                                    interaction_constraints=None,\n                                    learning_rate=None, m...\n                                    max_cat_to_onehot=None, max_delta_step=None,\n                                    max_depth=None, max_leaves=None,\n                                    min_child_weight=None, missing=nan,\n                                    monotone_constraints=None,\n                                    multi_strategy=None, n_estimators=None,\n                                    n_jobs=None, num_parallel_tree=None,\n                                    random_state=None, ...),\n             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n                         'max_depth': [3, 4, 5],\n                         'n_estimators': [100, 200, 300]},\n             scoring='neg_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5,\n             estimator=XGBRegressor(base_score=None, booster=None,\n                                    callbacks=None, colsample_bylevel=None,\n                                    colsample_bynode=None,\n                                    colsample_bytree=None, device=None,\n                                    early_stopping_rounds=None,\n                                    enable_categorical=False, eval_metric=None,\n                                    feature_types=None, gamma=None,\n                                    grow_policy=None, importance_type=None,\n                                    interaction_constraints=None,\n                                    learning_rate=None, m...\n                                    max_cat_to_onehot=None, max_delta_step=None,\n                                    max_depth=None, max_leaves=None,\n                                    min_child_weight=None, missing=nan,\n                                    monotone_constraints=None,\n                                    multi_strategy=None, n_estimators=None,\n                                    n_jobs=None, num_parallel_tree=None,\n                                    random_state=None, ...),\n             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n                         'max_depth': [3, 4, 5],\n                         'n_estimators': [100, 200, 300]},\n             scoring='neg_mean_squared_error')estimator: XGBRegressorXGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)XGBRegressorXGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)\n\n\n\nbest_model = grid_search.best_estimator_\nbest_model\n\nXGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=5, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=300, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.XGBRegressorXGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=5, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=300, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)\n\n\n\n\n\n\nbest_model.score(X_test, y_test)\n\n0.8850799773550728\n\n\n\ny_xgb_test_pred = best_model.predict(X_test)\n\n\nxgb_test_rmse = np.sqrt(mean_squared_error(y_test, y_xgb_test_pred))\nxgb_test_rmse\n\n218.81726410952444\n\n\n\n\n\n\nX_test['pred'] = y_xgb_test_pred\nX_test.loc[X_test['Functioning Day_Yes'] == 0, 'pred'] = 0\nX_test.loc[X_test[\"pred\"] &lt; 0, \"pred\"] = 0\nX_test\n\n\n\n\n\n\n\n\nHour\nTemperature(°C)\nHumidity(%)\nWind speed (m/s)\nVisibility (10m)\nDew point temperature(°C)\nSolar Radiation (MJ/m2)\nRainfall(mm)\nSnowfall (cm)\nHoliday_No Holiday\nSeasons_Spring\nSeasons_Summer\nSeasons_Winter\nFunctioning Day_Yes\nDay\nMonth\nYear\npred\n\n\n\n\n6056\n8\n27.2\n69\n1.8\n1999\n21.0\n0.70\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n10\n8\n2018\n1524.514648\n\n\n5556\n12\n32.6\n51\n2.1\n800\n21.1\n3.21\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n20\n7\n2018\n732.632812\n\n\n5990\n14\n34.0\n50\n1.2\n1744\n22.1\n1.68\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n7\n8\n2018\n712.731140\n\n\n7674\n18\n16.9\n47\n1.4\n1637\n5.5\n0.11\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n16\n10\n2018\n2194.891357\n\n\n3319\n7\n6.4\n51\n1.0\n1398\n-3.0\n0.19\n0.0\n0.0\nTrue\nTrue\nFalse\nFalse\nTrue\n18\n4\n2018\n639.635742\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n8307\n3\n4.6\n65\n0.1\n2000\n-1.4\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n12\n11\n2018\n292.208466\n\n\n100\n4\n-7.2\n34\n3.0\n2000\n-20.4\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n5\n12\n2017\n89.085770\n\n\n6605\n5\n20.6\n65\n1.1\n2000\n13.7\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nFalse\nTrue\n2\n9\n2018\n266.967682\n\n\n1783\n7\n-7.2\n70\n1.9\n1946\n-11.7\n0.00\n0.0\n0.0\nTrue\nFalse\nFalse\nTrue\nTrue\n13\n2\n2018\n220.198990\n\n\n6013\n13\n34.4\n48\n2.1\n1921\n21.7\n2.37\n0.0\n0.0\nTrue\nFalse\nTrue\nFalse\nTrue\n8\n8\n2018\n663.002563\n\n\n\n\n1752 rows × 18 columns\n\n\n\n\nnp.sqrt(mean_squared_error(y_test, X_test[\"pred\"]))\n\n217.4355409172396\n\n\n\npred_df = X_test[['pred']]\npred_df = pred_df.reset_index(drop=True)\npred_df.insert(0, 'id', range(1, len(pred_df) + 1))\npred_df\n\n\n\n\n\n\n\n\nid\npred\n\n\n\n\n0\n1\n1524.514648\n\n\n1\n2\n732.632812\n\n\n2\n3\n712.731140\n\n\n3\n4\n2194.891357\n\n\n4\n5\n639.635742\n\n\n...\n...\n...\n\n\n1747\n1748\n292.208466\n\n\n1748\n1749\n89.085770\n\n\n1749\n1750\n266.967682\n\n\n1750\n1751\n220.198990\n\n\n1751\n1752\n663.002563\n\n\n\n\n1752 rows × 2 columns\n\n\n\n\npred_df.to_csv('pred_values.csv', index = False)"
  },
  {
    "objectID": "posts/Goldener-Topf_Analyse/goto.html",
    "href": "posts/Goldener-Topf_Analyse/goto.html",
    "title": "Mini-Textanalyse DS",
    "section": "",
    "text": "library(tokenizers)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(ggthemes)\nlibrary(topicmodels)\nlibrary(tm)\n\n\n\nTextanalyse von E.T.A-Hoffmanns “Der goldene Topf”.\n\ntopf &lt;- read.delim2(\"https://www.gutenberg.org/cache/epub/17362/pg17362.txt\")\ntopf &lt;- as_tibble(topf)\ntopf &lt;- topf[-c(1:24, 2678:2979), ]\ntopf\n\n# A tibble: 2,653 × 1\n   The.Project.Gutenberg.eBook.of.Der.Goldene.Topf                  \n   &lt;chr&gt;                                                            \n 1 DER GOLDENE TOPF                                                 \n 2 von                                                              \n 3 E.T.A. HOFFMANN:                                                 \n 4 Mit 11 Federzeichnungen von Edmund Schaefer                      \n 5 [Illustration: Titelbild. Die Frauenkirche in Dresden]           \n 6 Erstes bis fünftes Tausend                                       \n 7 Verlag von Gustav Kiepenheuer Weimar 1913                        \n 8 ERSTE VIGILIE.                                                   \n 9 Die Unglücksfälle des Studenten Anselmus. Des Konrektors Paulmann\n10 Sanitätsknaster und die goldgrünen Schlangen.                    \n# ℹ 2,643 more rows\n\n\n\n\n\ntopf_token &lt;- topf %&gt;% \n  unnest_tokens(output = token, input = The.Project.Gutenberg.eBook.of.Der.Goldene.Topf) %&gt;% \n  filter(str_detect(token, \"[a-z]\"))\ntopf_token\n\n# A tibble: 29,219 × 1\n   token           \n   &lt;chr&gt;           \n 1 der             \n 2 goldene         \n 3 topf            \n 4 von             \n 5 e.t.a           \n 6 hoffmann        \n 7 mit             \n 8 federzeichnungen\n 9 von             \n10 edmund          \n# ℹ 29,209 more rows\n\n\n\n\n\n\ndata(stopwords_de, package = \"lsa\")\n\nstopwords_de &lt;- tibble(word = stopwords_de)\n\nstopwords_de &lt;- stopwords_de %&gt;% \n  rename(token = word)  \n\ntopf_token &lt;- topf_token %&gt;% \n  anti_join(stopwords_de)\n\nJoining with `by = join_by(token)`\n\ntopf_token %&gt;% \n  count(token, sort = TRUE) %&gt;% \n  print()\n\n# A tibble: 5,508 × 2\n   token           n\n   &lt;chr&gt;       &lt;int&gt;\n 1 er            446\n 2 anselmus      291\n 3 archivarius   160\n 4 denn          151\n 5 du            144\n 6 nun           137\n 7 ihn           118\n 8 veronika      105\n 9 student        97\n10 wohl           94\n# ℹ 5,498 more rows\n\n\n\n\n\n\n\ndata(sentiws, package = \"pradadata\")\ntopf_senti &lt;- topf_token %&gt;% \n  inner_join(sentiws, by = c(\"token\" = \"word\")) %&gt;% \n  select(-inflections)\n\nWarning in inner_join(., sentiws, by = c(token = \"word\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 2698 of `x` matches multiple rows in `y`.\nℹ Row 3187 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ntopf_senti\n\n# A tibble: 600 × 3\n   token     neg_pos   value\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n 1 glücklich pos      0.115 \n 2 besonders pos      0.539 \n 3 schnell   pos      0.117 \n 4 lachen    pos      0.0135\n 5 entziehen neg     -0.0048\n 6 weise     pos      0.224 \n 7 festlich  pos      0.202 \n 8 kurz      neg     -0.0048\n 9 langsam   neg     -0.0167\n10 einsam    neg     -0.163 \n# ℹ 590 more rows\n\n\n\ntopf_senti %&gt;%\n  count(token, neg_pos, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  group_by(neg_pos) %&gt;%\n  slice_max(n, n = 10)%&gt;%\n  ungroup() %&gt;%\n  mutate(token = reorder(token, n)) %&gt;%\n  ggplot(aes(n, token, fill = neg_pos)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~neg_pos, scales = \"free_y\") +\n  labs(x = \"Häufigkeit\",\n       y = \"Wort\") +\n  theme_minimal() +\n  scale_fill_tableau(palette = \"Nuriel Stone\")\n\n\n\n\n\ntopf_senti %&gt;% \n  group_by(neg_pos) %&gt;% \n  summarise(polarity_sum = sum(value),\n            polarity_count = n()) %&gt;% \n  mutate(polarity_prop = (polarity_count / sum(polarity_count)) %&gt;% \n           round(2))\n\n# A tibble: 2 × 4\n  neg_pos polarity_sum polarity_count polarity_prop\n  &lt;chr&gt;          &lt;dbl&gt;          &lt;int&gt;         &lt;dbl&gt;\n1 neg            -29.5            184          0.31\n2 pos             72.3            416          0.69\n\n\n\ntopf_senti %&gt;% \n  distinct(token, .keep_all = TRUE) %&gt;% \n  mutate(value_abs = abs(value)) %&gt;%\n  group_by(neg_pos) %&gt;%\n  top_n(10, value_abs) %&gt;%\n  mutate(token = reorder(token, value_abs)) %&gt;%\n  ggplot(aes(value_abs, token, fill = neg_pos)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~neg_pos, scales = \"free_y\") +\n  labs(x = \"Effektstärke\",\n       y = \"Wort\") +\n  theme_minimal() +\n  scale_fill_tableau(palette = \"Nuriel Stone\")\n\n\n\n\n\n\n\nHäufigkeiten der Bigramme\n\ntopf_bigram &lt;- \n  topf %&gt;%\n  unnest_tokens(bigram, The.Project.Gutenberg.eBook.of.Der.Goldene.Topf, token = \"ngrams\", n = 2) %&gt;%\n  filter(!is.na(bigram))\n\n\ntopf_bigram %&gt;% \ncount(bigram, sort = TRUE) %&gt;% \n  print()\n\n# A tibble: 19,046 × 2\n   bigram                    n\n   &lt;chr&gt;                 &lt;int&gt;\n 1 in der                   89\n 2 der student              85\n 3 student anselmus         77\n 4 archivarius lindhorst    72\n 5 der archivarius          67\n 6 in den                   49\n 7 in die                   49\n 8 der konrektor            46\n 9 in dem                   46\n10 konrektor paulmann       46\n# ℹ 19,036 more rows\n\n\n\n\n\ntopf_bigra_sep &lt;- topf_bigram %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")%&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\ntopf_bigra_sep %&gt;%\n  unite(bigram, word1, word2, sep = \" \") %&gt;%\n  count(bigram, sort = TRUE) %&gt;%\n  slice_max(n, n = 10)%&gt;%\n  mutate(bigram = reorder(bigram, n)) %&gt;%\n  ggplot(aes(n, bigram)) +\n  geom_col(fill = \"#8175aa\") +\n  labs(x = \"Häufigkeit\",\n       y = \"Bigram\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nVerneinungen &lt;- c(\"nicht\", \"nie\", \"niemals\", \"keine\", \"kein\")\n\ntopf_bigra_sep %&gt;%\n  filter(word1 %in% Verneinungen) %&gt;%\n  inner_join(sentiws, by = c(word2 = \"word\")) %&gt;%\n  count(word1, word2, value, sort = TRUE) %&gt;% \n  mutate(Beitrag = n * value) %&gt;%\n  arrange(desc(abs(Beitrag))) %&gt;%\n  head(20) %&gt;%\n  mutate(word2 = reorder(word2, Beitrag)) %&gt;%\n  ggplot(aes(n * value, word2, fill = n * value &gt; 0)) +\n  geom_col(show.legend = FALSE) +\n  labs(x = \"Sentiment-Wert * Häufigkeit\",\n       y = \"Verneinungen\") +\n  theme_minimal()+\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\n\n\n\n\n\ntopf_dtm &lt;- DocumentTermMatrix(topf_token)\ntopf_lda &lt;- LDA(topf_dtm, k = 4, control = list(seed = 42))\n\n\ntopf_themen &lt;- tidy(topf_lda, matrix = \"beta\")\n\ntopf_themen &lt;- topf_themen %&gt;%\n  group_by(topic) %&gt;%\n  slice_max(beta, n = 10) %&gt;% \n  ungroup() %&gt;%\n  arrange(topic, -beta)\n\ntopf_themen %&gt;%\n  mutate(term = reorder_within(term, beta, topic)) %&gt;%\n  ggplot(aes(beta, term, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ topic, scales = \"free\") +\n  scale_y_reordered() +\n  theme_minimal() +\n  scale_fill_tableau(\"Nuriel Stone\")"
  },
  {
    "objectID": "posts/Goldener-Topf_Analyse/goto.html#datenimport",
    "href": "posts/Goldener-Topf_Analyse/goto.html#datenimport",
    "title": "Mini-Textanalyse DS",
    "section": "",
    "text": "Textanalyse von E.T.A-Hoffmanns “Der goldene Topf”.\n\ntopf &lt;- read.delim2(\"https://www.gutenberg.org/cache/epub/17362/pg17362.txt\")\ntopf &lt;- as_tibble(topf)\ntopf &lt;- topf[-c(1:24, 2678:2979), ]\ntopf\n\n# A tibble: 2,653 × 1\n   The.Project.Gutenberg.eBook.of.Der.Goldene.Topf                  \n   &lt;chr&gt;                                                            \n 1 DER GOLDENE TOPF                                                 \n 2 von                                                              \n 3 E.T.A. HOFFMANN:                                                 \n 4 Mit 11 Federzeichnungen von Edmund Schaefer                      \n 5 [Illustration: Titelbild. Die Frauenkirche in Dresden]           \n 6 Erstes bis fünftes Tausend                                       \n 7 Verlag von Gustav Kiepenheuer Weimar 1913                        \n 8 ERSTE VIGILIE.                                                   \n 9 Die Unglücksfälle des Studenten Anselmus. Des Konrektors Paulmann\n10 Sanitätsknaster und die goldgrünen Schlangen.                    \n# ℹ 2,643 more rows\n\n\n\n\n\ntopf_token &lt;- topf %&gt;% \n  unnest_tokens(output = token, input = The.Project.Gutenberg.eBook.of.Der.Goldene.Topf) %&gt;% \n  filter(str_detect(token, \"[a-z]\"))\ntopf_token\n\n# A tibble: 29,219 × 1\n   token           \n   &lt;chr&gt;           \n 1 der             \n 2 goldene         \n 3 topf            \n 4 von             \n 5 e.t.a           \n 6 hoffmann        \n 7 mit             \n 8 federzeichnungen\n 9 von             \n10 edmund          \n# ℹ 29,209 more rows\n\n\n\n\n\n\ndata(stopwords_de, package = \"lsa\")\n\nstopwords_de &lt;- tibble(word = stopwords_de)\n\nstopwords_de &lt;- stopwords_de %&gt;% \n  rename(token = word)  \n\ntopf_token &lt;- topf_token %&gt;% \n  anti_join(stopwords_de)\n\nJoining with `by = join_by(token)`\n\ntopf_token %&gt;% \n  count(token, sort = TRUE) %&gt;% \n  print()\n\n# A tibble: 5,508 × 2\n   token           n\n   &lt;chr&gt;       &lt;int&gt;\n 1 er            446\n 2 anselmus      291\n 3 archivarius   160\n 4 denn          151\n 5 du            144\n 6 nun           137\n 7 ihn           118\n 8 veronika      105\n 9 student        97\n10 wohl           94\n# ℹ 5,498 more rows"
  },
  {
    "objectID": "posts/Goldener-Topf_Analyse/goto.html#sentimentanalyse",
    "href": "posts/Goldener-Topf_Analyse/goto.html#sentimentanalyse",
    "title": "Mini-Textanalyse DS",
    "section": "",
    "text": "data(sentiws, package = \"pradadata\")\ntopf_senti &lt;- topf_token %&gt;% \n  inner_join(sentiws, by = c(\"token\" = \"word\")) %&gt;% \n  select(-inflections)\n\nWarning in inner_join(., sentiws, by = c(token = \"word\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 2698 of `x` matches multiple rows in `y`.\nℹ Row 3187 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ntopf_senti\n\n# A tibble: 600 × 3\n   token     neg_pos   value\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n 1 glücklich pos      0.115 \n 2 besonders pos      0.539 \n 3 schnell   pos      0.117 \n 4 lachen    pos      0.0135\n 5 entziehen neg     -0.0048\n 6 weise     pos      0.224 \n 7 festlich  pos      0.202 \n 8 kurz      neg     -0.0048\n 9 langsam   neg     -0.0167\n10 einsam    neg     -0.163 \n# ℹ 590 more rows\n\n\n\ntopf_senti %&gt;%\n  count(token, neg_pos, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  group_by(neg_pos) %&gt;%\n  slice_max(n, n = 10)%&gt;%\n  ungroup() %&gt;%\n  mutate(token = reorder(token, n)) %&gt;%\n  ggplot(aes(n, token, fill = neg_pos)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~neg_pos, scales = \"free_y\") +\n  labs(x = \"Häufigkeit\",\n       y = \"Wort\") +\n  theme_minimal() +\n  scale_fill_tableau(palette = \"Nuriel Stone\")\n\n\n\n\n\ntopf_senti %&gt;% \n  group_by(neg_pos) %&gt;% \n  summarise(polarity_sum = sum(value),\n            polarity_count = n()) %&gt;% \n  mutate(polarity_prop = (polarity_count / sum(polarity_count)) %&gt;% \n           round(2))\n\n# A tibble: 2 × 4\n  neg_pos polarity_sum polarity_count polarity_prop\n  &lt;chr&gt;          &lt;dbl&gt;          &lt;int&gt;         &lt;dbl&gt;\n1 neg            -29.5            184          0.31\n2 pos             72.3            416          0.69\n\n\n\ntopf_senti %&gt;% \n  distinct(token, .keep_all = TRUE) %&gt;% \n  mutate(value_abs = abs(value)) %&gt;%\n  group_by(neg_pos) %&gt;%\n  top_n(10, value_abs) %&gt;%\n  mutate(token = reorder(token, value_abs)) %&gt;%\n  ggplot(aes(value_abs, token, fill = neg_pos)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~neg_pos, scales = \"free_y\") +\n  labs(x = \"Effektstärke\",\n       y = \"Wort\") +\n  theme_minimal() +\n  scale_fill_tableau(palette = \"Nuriel Stone\")"
  },
  {
    "objectID": "posts/Goldener-Topf_Analyse/goto.html#n-gram---analyse",
    "href": "posts/Goldener-Topf_Analyse/goto.html#n-gram---analyse",
    "title": "Mini-Textanalyse DS",
    "section": "",
    "text": "Häufigkeiten der Bigramme\n\ntopf_bigram &lt;- \n  topf %&gt;%\n  unnest_tokens(bigram, The.Project.Gutenberg.eBook.of.Der.Goldene.Topf, token = \"ngrams\", n = 2) %&gt;%\n  filter(!is.na(bigram))\n\n\ntopf_bigram %&gt;% \ncount(bigram, sort = TRUE) %&gt;% \n  print()\n\n# A tibble: 19,046 × 2\n   bigram                    n\n   &lt;chr&gt;                 &lt;int&gt;\n 1 in der                   89\n 2 der student              85\n 3 student anselmus         77\n 4 archivarius lindhorst    72\n 5 der archivarius          67\n 6 in den                   49\n 7 in die                   49\n 8 der konrektor            46\n 9 in dem                   46\n10 konrektor paulmann       46\n# ℹ 19,036 more rows\n\n\n\n\n\ntopf_bigra_sep &lt;- topf_bigram %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")%&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\ntopf_bigra_sep %&gt;%\n  unite(bigram, word1, word2, sep = \" \") %&gt;%\n  count(bigram, sort = TRUE) %&gt;%\n  slice_max(n, n = 10)%&gt;%\n  mutate(bigram = reorder(bigram, n)) %&gt;%\n  ggplot(aes(n, bigram)) +\n  geom_col(fill = \"#8175aa\") +\n  labs(x = \"Häufigkeit\",\n       y = \"Bigram\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nVerneinungen &lt;- c(\"nicht\", \"nie\", \"niemals\", \"keine\", \"kein\")\n\ntopf_bigra_sep %&gt;%\n  filter(word1 %in% Verneinungen) %&gt;%\n  inner_join(sentiws, by = c(word2 = \"word\")) %&gt;%\n  count(word1, word2, value, sort = TRUE) %&gt;% \n  mutate(Beitrag = n * value) %&gt;%\n  arrange(desc(abs(Beitrag))) %&gt;%\n  head(20) %&gt;%\n  mutate(word2 = reorder(word2, Beitrag)) %&gt;%\n  ggplot(aes(n * value, word2, fill = n * value &gt; 0)) +\n  geom_col(show.legend = FALSE) +\n  labs(x = \"Sentiment-Wert * Häufigkeit\",\n       y = \"Verneinungen\") +\n  theme_minimal()+\n  scale_fill_tableau(\"Nuriel Stone\")"
  },
  {
    "objectID": "posts/Goldener-Topf_Analyse/goto.html#themenanalyse",
    "href": "posts/Goldener-Topf_Analyse/goto.html#themenanalyse",
    "title": "Mini-Textanalyse DS",
    "section": "",
    "text": "topf_dtm &lt;- DocumentTermMatrix(topf_token)\ntopf_lda &lt;- LDA(topf_dtm, k = 4, control = list(seed = 42))\n\n\ntopf_themen &lt;- tidy(topf_lda, matrix = \"beta\")\n\ntopf_themen &lt;- topf_themen %&gt;%\n  group_by(topic) %&gt;%\n  slice_max(beta, n = 10) %&gt;% \n  ungroup() %&gt;%\n  arrange(topic, -beta)\n\ntopf_themen %&gt;%\n  mutate(term = reorder_within(term, beta, topic)) %&gt;%\n  ggplot(aes(beta, term, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ topic, scales = \"free\") +\n  scale_y_reordered() +\n  theme_minimal() +\n  scale_fill_tableau(\"Nuriel Stone\")"
  }
]