{
  "hash": "9b549cdeecabf9f48868e0a948e4b700",
  "result": {
    "markdown": "---\ntitle: \"Hate Speech auf Reddit\"\nauthor: \"Raphael Balzer\"\ndate: \"2024-01-12\"\nformat:\n  html:\n    toc: true\n    number-sections: true\n    theme: minty\n---\n\n\nZiel dieser Analyse ist es, die Reddit-Threads, deren ursprüngliche Posts das Stichwort \"Kanye West\" enthalten, in Bezug auf Sentiment, Wortwahl und Hate-Speech zu untersuchen. Hierbei ist vor allem die Veränderung der Sentimente der Posts im Zeitverlauf interessant. Dieser Post soll außerdem der Antwort auf die Frage näherkommen, ob die Nutzung der kostenlosen Reddit-API eine Alternative zur inzwischen kostenpflichtigen Twitter-API darstellt, um Hate Speech auf Social-Media-Plattformen zu analysieren. Der Post lässt sich grob in zwei Teile gliedern, nämlich wird zunächst die Analyse der Posts und Kommentare in Bezug auf Sentimente und Themen vorgenommen, woraufhin die Beiträge auf im zweiten Teil auf Hate Speech geprüft werden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tokenizers)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(textdata)\nlibrary(ggthemes)\nlibrary(topicmodels)\nlibrary(tm)\nlibrary(stringr)\nlibrary(RedditExtractoR)\nlibrary(httr)\n```\n:::\n\n\n# Analyse der Posts und Kommentare\n\n## Laden der Posts\n\nDie Posts werden mit Hilfe des Pakets `RedditExtractoR`, welches die Reddit-API anspricht, extrahiert. Ich lade alle Posts, die das Keyword \"Kanye West\" enthalten (und innerhalb des Download-Limits sind). Dadurch dass ich das API Download-Limit für heute bereits erreicht habe, importiere ich die Posts und Kommentare als Csv-Datei.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposts <- find_thread_urls(\n  keywords = \"Kanye West\",\n  sort_by=\"top\", \n  period = \"all\"\n  )\nstr(posts)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nposts <- read_csv(\"posts.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\nRows: 228 Columns: 8\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(5): ...1, title, text, subreddit, url dbl (2): timestamp, comments date (1):\ndate_utc\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n```\n:::\n:::\n\n\n\n## Laden der Kommentare\n\nMit der Funktion `get_thread_content()` ist es möglich, bis zu 500 Kommentare zu einer Post-URL herunterzuladen. Um maximal 500 Kommentare zu allen n Posts herunterzuladen, wende ich eine Schleife an. Die Ausgabe ist dann eine Liste, die zwei Dataframes enthält. Ich extrahiere den Dataframe `comments` und speichere jeden Dataframe zu jeder URL in einer Liste ab. Manchmal kann es zu Problemen bei der Zusammenführung der Listenelemente zu einem Dataframe kommen, da die Spalte `comment_id` in manchen Fällen von der Standardfornatierung als Character abweicht und als Integer gespeichert wird. Dieses Problem löse ich, indem ich alle solche Spalten in Character umwandle. Zuletzt entferne ich noch sowohl alle entfernten und gelöschten Posts als auch Links und Zahlen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomments_list <- list()\n\nfor (i in 1:nrow(posts)) {\n  comments <- get_thread_content(posts$url[i])$comments\n  comments_list[[i]] <- comments\n}\n\numwandlung_character <- function(df) {\n  if (\"comment_id\" %in% names(df) && is.integer(df$comment_id)) {\n    df$comment_id <- as.character(df$comment_id)\n  }\n  return(df)\n}\n\nliste_dataframes_umgewandelt <- lapply(comments_list, umwandlung_character)\nall_comments <- bind_rows(liste_dataframes_umgewandelt)\nall_comments <- all_comments %>%\n  mutate(comment = str_remove_all(comment, pattern = 'http[s]?://\\\\S+|\\\\d+')) %>%\n  mutate(timestamp = as_datetime(timestamp, origin = \"1970-01-01\")) %>% \n  select(timestamp, comment, comment_id, url)\nall_comments <- all_comments %>%\n  filter(!grepl(\"\\\\[deleted\\\\]|\\\\[removed\\\\]\", comment))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nall_comments <- read_csv(\"all_comments.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\nRows: 98044 Columns: 5\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(3): comment, comment_id, url dbl (2): ...1, timestamp\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n```\n:::\n:::\n\n\nIm Folgenden werden die Kommentare und Posts einzeln betrachtet. Dies hat den Grund, dass Reddit-Posts tendenziell mehr aus sachlichen Inhalten bestehen, während die Kommentarsektion inhaltlich freier und dadaurch, dass sich dort noch einmal ganz eigene Themen entspinnen, nicht mit den Posts vergleichbar sind. Hinzu kommt, dass die Anzahl der Kommentare die der Posts um ein Vielfaches übersteigt, sodass diese separat analysiert werden sollten.\n\n## Tokenisierung\n\nIm Folgenden wandle ich die Posts und Kommentare in Tokens um, entferne alle Links und Zahlen und wandle `timestamp` in ein Datumsobjekt um. Um alle Text-Inhalte der Posts zu erfassen, vereine ich die Titel der Posts mit den Posts, da es viele Posts gibt, deren Kernaussage im Titel steht, die durch ein Bild verdeutlicht wird.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoststoken <- posts %>%\n  unite(text, c(title, text)) %>%\n  mutate(text = str_remove_all(text, pattern = '\"http[s]?://\\\\S+\"|\\\\d+')) %>%\n  mutate(timestamp = as_datetime(timestamp, origin = \"1970-01-01\")) %>% \n  unnest_tokens(word, text)\nnrow(poststoken)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 22897\n```\n:::\n\n```{.r .cell-code}\nlength(unique(poststoken$id))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `id`.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncommstoken <- all_comments %>%\n  mutate(timestamp = as_datetime(timestamp, origin = \"1970-01-01\")) %>% \n  unnest_tokens(word, comment)\n```\n:::\n\n\n## Entfernung der Stopwords\n\nNun werden alle Stopwords entfernt. Ich gehe davon aus, dass die Kommentare und Posts fast ausschließlich englischer Sprache sind. Für den Fall, dass sich im Datensatz jedoch sowohl deutsch- als auch englischsprachige Posts finden, kombiniere ich zwei Stopwords-Lexika (deutsch und englisch) zu einem.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(stopwords_de, package = \"lsa\")\ndata(stopwords_en, package = \"lsa\")\nstopwords_en <- tibble(word = stopwords_en)\nstopwords_de <- tibble(word = stopwords_de)\nstopwords <- bind_rows(stopwords_de, stopwords_en)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npoststoken <- poststoken %>%\n  anti_join(stopwords)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(word)`\n```\n:::\n\n```{.r .cell-code}\nnrow(poststoken)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 12280\n```\n:::\n\n```{.r .cell-code}\nlength(unique(poststoken$id))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `id`.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncommstoken <- commstoken %>%\n  anti_join(stopwords)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(word)`\n```\n:::\n:::\n\n\n## Sentimentanalyse\n\nFür die Sentimentanalyse gilt dasselbe wie für das Stopwords-Lexikon: Ich möchte, dass es zweisprachig ist. Die gewählten Lexika `afinn` und `sentiws` haben jedoch nicht dieselbe Skalierung, weshalb ich noch eine Min-Max-Normalisierung vornehme, um eine Vergleichbarkeit der deutschen und englischen Sentimentwerte zu gewährleisten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsenti_en <- get_sentiments(\"afinn\") %>% \n  mutate(neg_pos = case_when(value > 0 ~ \"pos\",\n                             TRUE ~ \"neg\"))\n\ndata(sentiws, package = \"pradadata\")\nsentiws <- sentiws %>% \n  select(word, value, neg_pos)\n\nmin_max_normalize <- function(x, old_min, old_max, new_min, new_max) {\n  return (((x - old_min) / (old_max - old_min) * (new_max - new_min)) + new_min)\n}\n\nsenti_en <- senti_en %>% \n  mutate(value = min_max_normalize(value, -5, 5, -1, 1))\n\nsenti <- bind_rows(sentiws, senti_en)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npoststoken_senti <- poststoken %>%\ninner_join(senti)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(word)`\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in inner_join(., senti): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 88 of `x` matches multiple rows in `y`.\nℹ Row 4591 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n```\n:::\n\n```{.r .cell-code}\nnrow(poststoken_senti)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1269\n```\n:::\n\n```{.r .cell-code}\nlength(unique(poststoken_senti$timestamp))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 124\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncommstoken_senti <- commstoken %>% \n  inner_join(senti)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(word)`\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in inner_join(., senti): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 778 of `x` matches multiple rows in `y`.\nℹ Row 5008 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n```\n:::\n:::\n\n\n## Berechnung des Sentiments pro Jahr\n\nZuletzt werden noch die Sentimentwerte aller Posts in einem Jahr zusammengefasst und mit der Anzahl der Posts gewichtet.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npostssenti <- poststoken_senti %>% \n  mutate(year = year(timestamp)) %>%\n  group_by(year) %>%\n  summarize(value = mean(value),\n            postcount = length(unique((timestamp)))) %>% \n  mutate(sentiment = (value * postcount) / sum(postcount))\n\nnrow(postssenti)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncommssenti <- commstoken_senti %>%\n  mutate(year = year(timestamp)) %>% \n  group_by(year) %>% \n  summarize(value = mean(value),\n            postcount = length(unique((timestamp)))) %>% \n  mutate(sentiment = (value * postcount) / sum(postcount))\nnrow(commssenti)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npostssenti %>% \n  ggplot(aes(year, sentiment)) + \n  geom_line(linewidth = 1, colour = \"#6fb899\") +\n  labs(title = \"Sentimentwerte der Posts im Zeitverlauf\",\n       x = \"Jahr\",\n       y = \"Sentiment\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Hatespeech_Reddit_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncommssenti %>% \n  ggplot(aes(year, sentiment)) + \n  geom_line(linewidth = 1, colour = \"#6fb899\") +\n  scale_x_continuous(breaks = 2013:2024)+\n  labs(title = \"Sentimentwerte der Kommentare im Zeitverlauf\",\n       x = \"Jahr\",\n       y = \"Sentiment\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Hatespeech_Reddit_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nDie Sentimentwerte im Zeitverlauf sind überaus interessant. Auch wenn der Sentimentwert um den Nullbereich liegt, denke ich dennoch, dass er eine gewisse Aussagekraft hat. Gerade wenn er im Jahr 2022 sowohl bei den Posts als auch bei den Kommentaren rapide einbricht, um seinen absoluten Tiefpunkt zu erreichen, sollte man genauer hinsehen. Im Jahr 2022 stand es um die öffentliche Meinung zu Kanye West so schlecht wie noch nie zuvor. Durch ständige antisemitische Äußerungen, das Posten eines Hakenkreuzes und Tragen eines \"White Lifes Matter\"-Hoodies erreichte er die Sperrung seiner Social Media Accounts, die Kündigung der Kooperation mit Adidas und die Auslösung eines Shit-Storms in den sozialen Medien. Dieser Zusammenhang könnte obige Diagramme erklären.\n\n## Analyse der Sentimentwerte und -counts\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoststoken_senti %>%\n  count(word, neg_pos, sort = TRUE) %>%\n  ungroup() %>%\n  group_by(neg_pos) %>%\n  slice_max(n, n = 10)%>%\n  ungroup() %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(n, word, fill = neg_pos)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~neg_pos, scales = \"free_y\") +\n  labs(x = \"Häufigkeit\",\n       y = \"Wort\") +\n  theme_minimal() +\n  scale_fill_tableau(palette = \"Nuriel Stone\")\n```\n\n::: {.cell-output-display}\n![](Hatespeech_Reddit_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nDie häufigsten positiven Wörter sind insofern interessant, als sie den Themen des christlichen Glaubens widerspiegeln. Denn Kanye West bekennt sich regelmäßig in Interviews und Tweets zum Christentum. Inwiefern seine antisemitschen Äußerungen mit diesem Glauben vereinbar sind, sei mal dahingestellt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomms_bigram <- \n  all_comments %>%\n  unnest_tokens(bigram, comment, token = \"ngrams\", n = 2) %>%\n  filter(!is.na(bigram))\n\ncomms_bigram <- comms_bigram %>%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")%>%\n  filter(!word1 %in% stop_words$word) %>%\n  filter(!word2 %in% stop_words$word)\n\ncomms_bigram %>%\n  unite(bigram, word1, word2, sep = \" \") %>%\n  count(bigram, sort = TRUE) %>%\n  slice_max(n, n = 10)%>%\n  mutate(bigram = reorder(bigram, n)) %>%\n  ggplot(aes(n, bigram)) +\n  geom_col(fill = \"#8175aa\") +\n  labs(title = \"Bigramme nach Häufigkeit\",\n       x = \"Häufigkeit\",\n       y = \"Bigram\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Hatespeech_Reddit_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nInteressant ist bei der Betrachtung der häufigsten Bigramme, die in den Kommentaren vorkommen, wie präsent das Thema der psychischen Störungen ist. Die Mutmaßung, dass in den Kommentaren über Kanye Wests mentale Gesundheit diskutiert wird, ist nicht unplausibel.\n\n## Themenanalyse\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposts_dtm2 <- commstoken_senti %>% \n  mutate(timestamp = as_datetime(timestamp),\n         year = year(timestamp)) %>% \n  filter(year == 2022) %>%\n  select(word) %>% \n  DocumentTermMatrix(commstoken_senti)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `tokenize`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `tolower`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `stopwords`.\nUnknown or uninitialised column: `stopwords`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `dictionary`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `bounds`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `wordLengths`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `removePunctuation`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `removeNumbers`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `stemming`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `bounds`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `weighting`.\n```\n:::\n\n```{.r .cell-code}\nposts_lda2 <- LDA(posts_dtm2, k = 4, control = list(seed = 42))\n\nposts_themen2 <- tidy(posts_lda2, matrix = \"beta\")\n\nposts_themen2 <- posts_themen2 %>%\n  group_by(topic) %>%\n  slice_max(beta, n = 7) %>% \n  ungroup() %>%\n  arrange(topic, -beta)\n\nposts_themen2 %>%\n  mutate(term = reorder_within(term, beta, topic)) %>%\n  ggplot(aes(beta, term, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ topic, scales = \"free\") +\n  scale_y_reordered() +\n  labs(title = \"Kommentarthemen in 2022 \") +\n  theme_minimal() +\n  scale_fill_tableau(\"Nuriel Stone\")\n```\n\n::: {.cell-output-display}\n![](Hatespeech_Reddit_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nDie Analyse der Kommentarthemen des Jahres 2022 deuten ebenfalls auf Kanye Wests Äußerungen hin, da im ersten Thema dem Wort \"hitler\" eine gewisse Bedeutung zugeordnet wird.\n\n# Klassifikation von Hate Speech\n\nGerade in Zusammenhang mit konktroversen Themen und Personen ist die Analyse von Hate Speech in den sozialen Medien relevant. In Bezug auf die Kommentare zu Kanye West Posts ist es denke ich sehr interessant zu sehen, welcher Anteil der Kommentare als Hate Speech gilt. Für die Vorhersage wende ich Zero-Shot-Klassifikation mit Hilfe des vortrainierten Large Language Modells `LFTW R4 Target` von facebook an, welches ich über das Modul `transformers` von Huggingface anspreche, an.\n\n## Vorbereitung\n\nZunächst lade ich alle erforderlichen Module sowie das Modell. Der Code zur Verwendung des `pipeline`-Befehls wird hilfreicherweise von Huggingface bereitgestellt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'reticulate' was built under R version 4.2.3\n```\n:::\n\n```{.r .cell-code}\nuse_virtualenv(\"C:/Users/rapha/venv\")\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport tensorflow as tf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWARNING:tensorflow:From C:\\Users\\rapha\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n```\n:::\n\n```{.python .cell-code}\nfrom transformers import pipeline\n\nclassifier = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWARNING:tensorflow:From C:\\Users\\rapha\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n```\n:::\n:::\n\n\n## Anwendung\n\nFür die Klassifikation von Hate-Speech ziehe ich aus allen Kommentaren eine zufällige Stichprobe, da RoBERTa nur eine Maximallänge von 513 Inputs akzeptiert.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\ncomments_sample <- all_comments %>%\n  sample_n(size = 513, replace = FALSE)\n\ncomments_short <- comments_sample$comment\n```\n:::\n\n\nNun lade ich die Kommentare der Stichprobe in das Modell.\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncomments = r.comments_short\nresult = classifier(comments)\n```\n:::\n\n\nAnschließend füge ich der Stichprobe das Ergebnis der Klassifikation als neue Spalte hinzu.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresult <- py$result\nlabels <- lapply(result, function(element) element$label)\ncomments_hate <- cbind(comments_sample, hatespeech = unlist(labels)) %>%\n  select(timestamp, comment, hatespeech, comment_id, url)\n```\n:::\n\n\n## Analyse\n\nIm Folgenden untersuche ich die als Hate Speech klassifizierten Kommentare etwas näher, indem ich den Anteil der Hate Speech im Jahresverlauf sowie den Zusammenhang mit negativem Sentiment betrachte.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomments_hate %>%\n   count(hatespeech == \"hate\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"hatespeech == \\\"hate\\\"\"],\"name\":[1],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"FALSE\",\"2\":\"477\"},{\"1\":\"TRUE\",\"2\":\"36\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncomments_hate %>%\n  mutate(timestamp = as_datetime(timestamp, origin = \"1970-01-01\"),\n         year = year(timestamp)) %>%\n  group_by(year, hatespeech) %>%\n  count() %>%\n  ggplot(aes(x = year, y = n, fill = hatespeech)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Hatespeech-Kommentare im Zeitverlauf\",\n       x = \"Jahr\",\n       y = \"Anzahl\",\n       fill = \"Hate Speech\") +\n  scale_fill_tableau(\"Nuriel Stone\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Hatespeech_Reddit_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\nAuch wenn nur ein winziger Teil der Kommentare als Hate Speech klassifiziert wurde, ist in diesem Diagramm erkennbar, dass wieder im Jahr 2022 mit Abstand die meiste Hassrede auftrat.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncommstokensenti_hate <- comments_hate %>% \n  filter(hatespeech == \"hate\") %>% \n  unnest_tokens(word, comment) %>% \n  inner_join(senti)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(word)`\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in inner_join(., senti): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 541 of `x` matches multiple rows in `y`.\nℹ Row 4906 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n```\n:::\n\n```{.r .cell-code}\ncommstokensenti_hate %>% \n  summarise(mean(neg_pos == \"neg\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"mean(neg_pos == \\\"neg\\\")\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.423913\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncomments_hate %>% \n  filter(hatespeech == \"hate\") %>% \n  select(comment)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"comment\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"This man is bibolar and literally going insane and people are reacting like he's an exhibit at a zoo because of his reputation. As much as I love his music he shouldn't have become famous. It's damaging for him to be around yes men and having power. \\\\r\\\\n\\\\r\\\\nCompare this to how he was like  months ago when his latest album dropped. He made a wholesome music video about realising his dad had been his best friend all along. That's being bipolar in a nutshell\"},{\"1\":\"Jewish people will never understand what it's like to be persecuted like Ye.\"},{\"1\":\"Whodatmiami is a vintage HHH god. I can't compare to him cmon\"},{\"1\":\"Oh for sure but people lost moneg traveling to see it lost a night of their life and etc\"},{\"1\":\"I never understood 'the black vote', like all black people have to feel and vote a certain way because of the color of their skin.\"},{\"1\":\"hahahaha like how the fuck is woopedy scoop real like hahahaha just walk away from the poopity poop\"},{\"1\":\"South Park should do one of their paramount movies all about making fun of Kanye, really send that nutjob over the edge\"},{\"1\":\"Why doesn't he post on chan like the rest of the dysfunctional man-children\"},{\"1\":\"I respond with Yahtzees.\"},{\"1\":\"Silent Alarm by Bloc Party for me.\"},{\"1\":\"As someone that unfortunately lives in backwater FL, I agree. Miami is nice when you don\\\\031t count the coke heads and crazy ass driving.\"},{\"1\":\"Man if I was security and somebody Shaq size tried to rob the joint, I'd just help. Better than getting my ass beat =\\\\002\"},{\"1\":\"Well you see, the womenfolk get all hysterical and can't take care of themselves. /s\"},{\"1\":\"Allah just means god lol\"},{\"1\":\"I think business owner should consider their employee's public speech in their employability. But too many owner's are fine as long as the bottom line is fine. They believe he's worth millions in the hopes of him winning some shooty hoops. They don't really believe his speech is going to cost them more than he's worth in points. If they are ok with it, then the people have to make it known that we are not ok with it. And in this case it is ticket sales. \\\\r\\\\n\\\\r\\\\nBut there isn't much athletes can say that will keep fans from pouring into the stands. We have seen that. There is an accepted amount of bullshit we collectively will tolerate. Anti-Semitism isn't the taboo it should be. Hopefully no one loses their life after another person is inspired by these men to attack \\\"their masters\\\". \\\\r\\\\n\\\\r\\\\nI said the same thing Jon said about seeing it from a black persons perspective. Their culture has been taken from them over and over and for some it leaves them looking for a deeper root to their beginnings that must have been taken away from them. And punishing them for speaking their mind only reinforces the idea that Jewish people are in charge since they got pushback from speaking their mind. They have ignorance of the same thing happening in Europe in the past. Which lead to the most foul and profane things happening to good innocent people.\"},{\"1\":\"He listens to real rap, not these mumble C-Rappers. \\\\r\\\\n\\\\r\\\\nHis top five are Eminem, Slim Shady, half of Logic, NF, and Run the Jewels only when they're rapping about support Bernie Sanders.\"},{\"1\":\"ITT: Bitches.\"},{\"1\":\"Bitch, did you just shrink me, is you a hobbit? IS YOU A HOBBIT?\"},{\"1\":\"He meant his physical worth.. for his body parts. Because he was a white trump loving cracker and they are all black.\\\\r\\\\n\\\\r\\\\n/s\"},{\"1\":\"Wu tang clan wasn\\\\031t nothin to fuck with.\"},{\"1\":\"Slavery is a choice ass mutha fucker.\"},{\"1\":\"I always see this copy/pasted in the political subs, but does no one remember that he tried to have the guy helping killed with the Dildozer and the Ass Blaster? lol\"},{\"1\":\"If the guy possibly most famous for saying the phrase \\\" I love Hitler\\\" (rightmost in the photo) is at your church, you might just have a Nazi church on your hands.\"},{\"1\":\"Fuck you Kanye you psycho\"},{\"1\":\"how many Lil's are they? I lost count\"},{\"1\":\"Yes it's pretty crazy kyrie just can't say \\\"I'm sorry I posted that I was wrong.\\\" He really does thing he's a god or untouchable. Time to ban his ass.\"},{\"1\":\"&gt; but don't % of women wear a lot of makeup?\\\\r\\\\n\\\\r\\\\nThat's completely false. I'm sure in certain circles, it's more common than others, but I've never dated a girl that wore \\\"a lot\\\" of make-up. \\\\r\\\\n\\\\r\\\\n&gt;And what does Armenian have to do with anything? And I think most people would agree she happens to look just fine without makeup.\\\\r\\\\n\\\\r\\\\nI'm not attracted to Armenian women in general (I'm sure there are exceptions). But, it's no different than not being attracted to tall women or short women or fat women or skinny women. Their predisposition to certain physical characteristics aren't attractive to me. Everyone has different tastes and that's all that it comes down to.\"},{\"1\":\"\\\\034Gay fish y\\\\031all\\\\035 -  Kanye West aka Ye aka Gay Fish aka lyrical genius\"},{\"1\":\"Because Trump cares about black people x more than George Bush and the rest of the Rinos/Democrats?\"},{\"1\":\"AAAAAAHHHHHHHHHHHHHHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\"},{\"1\":\"BUM-BUM-BAH!\"},{\"1\":\"There\\\\031s plenty of gay fish in the sea.\"},{\"1\":\"I hate hot niggas act like you can't criticize a black celeb without being a white person in this sub's eyes. Ffs.\"},{\"1\":\"That Kaney hasnt existed for like a decade\"},{\"1\":\"Yep people forget about the shit MS pulled back in the day but it makes sense since people here weren't born then\"},{\"1\":\"I hate to tell you this but Shaq is also a world class Olympian level troll\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nNur die Hälfte der als Hassrede klassifizierten Kommentare haben ein negatives Sentiment. Außerdem halte ich persönlich Sätze wie \"You are an old one.\" nicht für Hate Speech. In Kombination mit dem Fakt, dass nur 34 von 513 Tweets als Hate Speech erkannt wurden, lassen mich diese Ergebnisse vermuten, dass das Modell nicht allzu zuverlässige Vorhersagen macht.\n\n# Fazit\n\nEs lässt sich sagen, dass die Analyse durchaus interessante Erkenntnisse hervorgebracht hat. Die Sentimentwerte können in einen klaren Zusammenhang mit dem Verhalten Kanye Wests gesetzt werden. Allerdings unterliegen diese Erkenntnisse starken Limitationen. Zum einen ist die Anzahl der verwertbaren Posts verschwindend gering, was die Aussagekraft der Analyse dieser beeinträchtigt. Deshalb lag das Augenmerk auch stärker auf den Kommentaren. Die Schwankungen in den Sentimentwerten beeinträchtigen ebenfalls die Aussagekraft der gewonnenen Erkenntnisse, da diese infinitesimal klein ausfallen. Die Klassifikationen des RoBERTa-Modells halte ich ebenfalls für stark ausbaufähig. Es wäre sinnvoll, in weiteren Analysen noch andere Large Language Modelle für diese Aufgabe auszuprobieren. Ziel der Analyse war es jedoch auch, zu sehen, ob Redditposts ähnlich interessant für die Analyse von Social-Media-Foren sind wie Tweets. Diese Frage ist auf jeden Fall mit Ja zu beantworten, zum einen aufgrund der leichten Zugänglichkeit und zum anderen aufgrund des regen Themenaustausches in den Threads, wie er hier beobachtet wurde.\n",
    "supporting": [
      "Hatespeech_Reddit_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}